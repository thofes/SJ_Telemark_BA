{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thofes/judging_SJ_BA/blob/main/Mark6_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHxXEr88Ra6k"
      },
      "outputs": [],
      "source": [
        "#Connect GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content.gdrive')\n",
        "\n",
        "#init Repository - YOLOv5\n",
        "%cd /content\n",
        "\n",
        "\n",
        "!git clone https://github.com/thofes/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "\n",
        "#init Repository - OpenPose\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "#Change the drive to my mounted gdrive\n",
        "%cd /content\n",
        "\n",
        "git_repo_url = 'https://github.com/thofes/openpose'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "\n",
        "if 1 or not exists(project_name):\n",
        "  !rm -rf openpose\n",
        "  # see: https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/949\n",
        "  print(\"install new CMake becaue of CUDA10\")\n",
        "  cmake_version = 'cmake-3.20.2-linux-x86_64.tar.gz'\n",
        "  if not exists(cmake_version):\n",
        "    !wget -q 'https://cmake.org/files/v3.20/{cmake_version}'\n",
        "  !tar xfz {cmake_version} --strip-components=1 -C /usr/local\n",
        "\n",
        "  print(\"clone openpose\")\n",
        "  !git clone -q --depth 1 $git_repo_url\n",
        "  print(\"install system dependencies\")\n",
        "  !apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev\n",
        "  print(\"build openpose\")\n",
        "  !cd openpose && rm -rf build || true && mkdir build && cd build && cmake .. && make -j`nproc`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content.gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZTZHh4PUknC",
        "outputId": "7820983e-7c7b-41eb-9562-098238739107"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content.gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QSl7fKevSZFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd26c4f-383b-494a-e62f-1773abc1d7ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NoTelemark', 'Telemark']\n",
            "/content.gdrive/My Drive/Train2/NoTelemark\n",
            "['01']\n",
            "/content.gdrive/My Drive/Train2/NoTelemark/01\n",
            "NoTelemark\n",
            "['NoTelemark', 'Telemark']\n",
            "BP\n",
            "/content.gdrive/My Drive/Train2/Telemark\n",
            "['02', '01']\n",
            "/content.gdrive/My Drive/Train2/Telemark/02\n",
            "Telemark\n",
            "['NoTelemark', 'Telemark']\n",
            "/content.gdrive/My Drive/Train2/Telemark/01\n",
            "Telemark\n",
            "['NoTelemark', 'Telemark']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "#Aufbau Json File genau anschauen\n",
        "\n",
        "json_path = \"/content.gdrive/My Drive//Train2/data.json\"\n",
        "#json_path = \"/content/data.json\"\n",
        "# dictionary to store mapping, labels, and Keypoints\n",
        "data = {\n",
        "    \"labels\":[],\n",
        "    \"keypoints\":[]\n",
        "}\n",
        "\n",
        "PATH = \"/content.gdrive/My Drive/Train2\"\n",
        "label= []\n",
        "try:\n",
        "    label = next(os.walk(PATH))[1]\n",
        "except StopIteration:\n",
        "    pass\n",
        "#data[\"labels\"].append(label)\n",
        "print(label)\n",
        "\n",
        "for l in label:\n",
        "  Path_jumpers = PATH + '/' + l\n",
        "  print(Path_jumpers)\n",
        "  Jumpers = []\n",
        "  try:\n",
        "    Jumpers = next(os.walk(Path_jumpers))[1]\n",
        "  except StopIteration:\n",
        "    pass\n",
        "  print(Jumpers)\n",
        "\n",
        "  for j in Jumpers:\n",
        "    Path_Pic = Path_jumpers + '/' + j\n",
        "    print(Path_Pic)\n",
        "\n",
        "    %cd /content/yolov5\n",
        "    !python detect.py --save-crop --source '{Path_Pic}' --project '{Path_Pic}' --save-txt\n",
        "\n",
        "    folder_dir = Path_Pic + '/exp'\n",
        "    %cd /content/openpose/build/examples/tutorial_api_python\n",
        "    !python3 04_keypoints_from_images.py --image_dir '{folder_dir}' --keypoint_scale 3 --no_display true\n",
        "\n",
        "    with open(Path_Pic + '/exp/keypoints.json', \"r\") as fp:\n",
        "        keypoints_json = json.load(fp)\n",
        "\n",
        "    data[\"keypoints\"].append(keypoints_json)\n",
        "\n",
        "    if l == 'NoTelemark':\n",
        "        data[\"labels\"].append(0)\n",
        "    if l == 'Telemark':\n",
        "        data[\"labels\"].append(1)    \n",
        "\n",
        "    #with open(Path_Pic + '/exp/keypoints.txt', \"r\") as keypointfile:\n",
        "        #keypoints = keypointfile.read()\n",
        "    #data[\"keypoints\"].append(keypoints)\n",
        "\n",
        "\n",
        "with open(json_path, \"w\") as fp:\n",
        "  json.dump(data, fp, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#test load data\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Train2/data.json', \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "# convert lists to numpy arrays\n",
        "X = np.array(data[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"labels\"])\n",
        "\n",
        "print(X)\n",
        "print(X.shape)\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9TXW6Gm35oc",
        "outputId": "24a822d7-ac0b-4a0c-f990-cf9d33de597d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.61342597 0.30372337 0.23925512 ... 0.52524942 0.71154225 0.54309702]\n",
            " [0.4108656  0.33063355 0.24723598 ... 0.4081504  0.68497944 0.33570752]\n",
            " [0.70509571 0.25489008 0.19814925 ... 0.59326494 0.7493878  0.5951854 ]]\n",
            "(3, 1575)\n",
            "[[0]\n",
            " [1]\n",
            " [1]]\n",
            "(3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# path to json file that stores MFCCs and genre labels for each processed segment\n",
        "DATA_PATH = \"/content.gdrive/MyDrive/Train2/data.json\"\n",
        "#DATA_PATH = '/content.gdrive/MyDrive/Musik/data_music.json'\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "        :param data_path (str): Path to json file containing data\n",
        "        :return X (ndarray): Inputs\n",
        "        :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    # convert lists to numpy arrays\n",
        "    X = np.array(data[\"keypoints\"])\n",
        "    #X = np.array(data[\"mfcc\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "\n",
        "    print(\"Data succesfully loaded!\")\n",
        "\n",
        "    return  X, y\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # load data\n",
        "    X, y = load_data(DATA_PATH)\n",
        "\n",
        "    print(X.shape)\n",
        "    print(y.shape)\n",
        "\n",
        "    # create train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "    print(X_train)\n",
        "    print(y_train)\n",
        "    print(X_test)\n",
        "    print(y_test)\n",
        "\n",
        "\n",
        "\n",
        "    # build network topology\n",
        "    model = keras.Sequential([\n",
        "\n",
        "        # input layer\n",
        "        #keras.layers.Flatten(input_shape=(X.shape[0], X.shape[1])),\n",
        "\n",
        "        # 1st dense layer\n",
        "        keras.layers.Dense(512, activation='relu', input_shape=(None,1,1575)),\n",
        "\n",
        "        # 2nd dense layer\n",
        "        keras.layers.Dense(256, activation='relu'),\n",
        "\n",
        "        # 3rd dense layer\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "\n",
        "        # output layer\n",
        "        keras.layers.Dense(2, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # compile model\n",
        "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=50)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFJJLr6EhMRM",
        "outputId": "d1318f19-00e8-4c00-9c48-2a75c0c3b7a7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data succesfully loaded!\n",
            "(3, 1575)\n",
            "(3, 1)\n",
            "[[0.61342597 0.30372337 0.23925512 ... 0.52524942 0.71154225 0.54309702]\n",
            " [0.4108656  0.33063355 0.24723598 ... 0.4081504  0.68497944 0.33570752]]\n",
            "[[0]\n",
            " [1]]\n",
            "[[0.70509571 0.25489008 0.19814925 ... 0.59326494 0.7493878  0.5951854 ]]\n",
            "[[1]]\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_145 (Dense)           (None, None, 1, 512)      806912    \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, None, 1, 256)      131328    \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, None, 1, 64)       16448     \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, None, 1, 2)        130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 954,818\n",
            "Trainable params: 954,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 1, 1575) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 1, 1575), dtype=tf.float32, name='dense_145_input'), name='dense_145_input', description=\"created by layer 'dense_145_input'\"), but it was called on an input with incompatible shape (None, 1575).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 1, 1575) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 1, 1575), dtype=tf.float32, name='dense_145_input'), name='dense_145_input', description=\"created by layer 'dense_145_input'\"), but it was called on an input with incompatible shape (None, 1575).\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7140 - accuracy: 0.5000WARNING:tensorflow:Model was constructed with shape (None, None, 1, 1575) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 1, 1575), dtype=tf.float32, name='dense_145_input'), name='dense_145_input', description=\"created by layer 'dense_145_input'\"), but it was called on an input with incompatible shape (None, 1575).\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.7140 - accuracy: 0.5000 - val_loss: 0.6343 - val_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4463 - accuracy: 1.0000 - val_loss: 0.7401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3119 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2410 - accuracy: 1.0000 - val_loss: 0.8340 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1881 - accuracy: 1.0000 - val_loss: 0.8288 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1497 - accuracy: 1.0000 - val_loss: 0.8249 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1211 - accuracy: 1.0000 - val_loss: 0.8390 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.8502 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.8596 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.8856 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.9296 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.9847 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 1.0508 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 1.1248 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.2662 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.3266 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.3815 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.4321 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.4789 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.5206 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.5593 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.5956 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.6293 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.6623 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.6939 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.7241 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7531 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7856 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.8206 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.8553 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8891 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.9219 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.9543 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.9863 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.0178 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.0485 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.0783 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1070 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1335 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1570 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.1788 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.1995 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2189 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2376 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2558 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2723 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2872 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3011 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3141 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = np.random.randint(10, size=(3, 1575))  # Three-dimensional array\n",
        "\n",
        "print(x3)\n",
        "\n",
        "print(\"x3 ndim: \", x3.ndim)\n",
        "print(\"x3 shape:\", x3.shape)\n",
        "print(\"x3 size: \", x3.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqMynruJatMi",
        "outputId": "ecb8bc53-53c5-4e24-aacb-f9a6f29737b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 1 0 ... 4 2 0]\n",
            " [0 6 5 ... 8 4 1]\n",
            " [3 6 7 ... 6 9 8]]\n",
            "x3 ndim:  2\n",
            "x3 shape: (3, 1575)\n",
            "x3 size:  4725\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mark6_dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOE3nDOSvNFEtUrFEyi2EM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}