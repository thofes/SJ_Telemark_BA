{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mark_NN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMo2f4gLGIU+ttMO3VBwfjz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thofes/judging_SJ_BA/blob/main/Mark_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Az5smJGhBU",
        "outputId": "664211aa-a324-4405-ff62-d66863720856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content.gdrive\n"
          ]
        }
      ],
      "source": [
        "#Connect GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content.gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import json files 1680 and reshape Achtung data_labeled_01042022 bereits richtig geshaped\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "PATH = \"/content.gdrive/MyDrive/Datasets_1680\"\n",
        "sets = []\n",
        "try:\n",
        "    sets = next(os.walk(PATH))[2]\n",
        "except StopIteration:\n",
        "    pass\n",
        "\n",
        "print(sets)\n",
        "X = np.empty(shape=(0,1680))\n",
        "y = np.empty(shape=0)\n",
        "\n",
        "print(X,y)\n",
        "\n",
        "for path in sets:\n",
        "    path = PATH + '/' + path\n",
        "    with open(path, \"r\") as fp:\n",
        "        data1 = json.load(fp)\n",
        "\n",
        "    # convert lists to numpy arrays\n",
        "    X1 = np.array(data1[\"keypoints\"])\n",
        "    #X = np.array(data[\"mfcc\"])\n",
        "    y1 = np.array(data1[\"labels\"])\n",
        "    X1 = np.reshape(X1, (y1.shape[0],1680))\n",
        "    X = np.concatenate((X,X1), axis=0)\n",
        "    y = np.concatenate((y,y1), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "#with np.printoptions(threshold=np.inf):\n",
        "    #print(X[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMw5fgEc1bF1",
        "outputId": "0105b420-b6e0-49e7-cf3e-f5b2e21fd86d"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data_Labeled_Max.json', 'data_Labeled_Mirror_Telemark_01042022.json', 'data_Labeled_Mirror_Telemark_09042022.json', 'data_Labeled_09042022.json']\n",
            "[] []\n",
            "(750, 1680)\n",
            "(750,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rearange array 5 BB 75 keypoints\n",
        "import json\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "#merging json files\n",
        "with open('/content.gdrive/MyDrive/Datasets_1680/data_Labeled_Max.json', \"r\") as fp:\n",
        "    data1 = json.load(fp)\n",
        "\n",
        "# convert lists to numpy arrays\n",
        "X = np.array(data1[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data1[\"labels\"])\n",
        "X = np.reshape(X, (y.shape[0],1680))\n",
        "\n",
        "print(X[0][0])\n",
        "\"\"\"\n",
        "idx = list(range(0,105))\n",
        "test = list(range(105,1680))\n",
        "try1 =[]\n",
        "print(idx)\n",
        "print(test)\n",
        "\n",
        "for i in range(21):\n",
        "    try1.append(idx[(i*5):(i*5)+5])\n",
        "    try1.append(test[(i*75):(i*75)+75])\n",
        "\n",
        "print(try1)\n",
        "\n",
        "\n",
        "flat_list = []\n",
        "for sublist in try1:\n",
        "    for item in sublist:\n",
        "        flat_list.append(item)\n",
        "\"\"\"\n",
        "with np.printoptions(threshold=np.inf):\n",
        "    X[0] = X[0][flat_list]\n",
        "    print(X[0])\n",
        "\"\"\"\n",
        "for i, x in enumerate(X):\n",
        "    X[i] = X[i][flat_list]\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "#with np.printoptions(threshold=np.inf):\n",
        "    #print(X[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmUdZbi8Vfas",
        "outputId": "f2fc1ea1-b75a-4500-e8a7-7a073c00811f"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104]\n",
            "[105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679]\n",
            "[[0, 1, 2, 3, 4], [105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], [5, 6, 7, 8, 9], [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254], [10, 11, 12, 13, 14], [255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329], [15, 16, 17, 18, 19], [330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404], [20, 21, 22, 23, 24], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479], [25, 26, 27, 28, 29], [480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554], [30, 31, 32, 33, 34], [555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629], [35, 36, 37, 38, 39], [630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704], [40, 41, 42, 43, 44], [705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779], [45, 46, 47, 48, 49], [780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854], [50, 51, 52, 53, 54], [855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929], [55, 56, 57, 58, 59], [930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004], [60, 61, 62, 63, 64], [1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079], [65, 66, 67, 68, 69], [1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154], [70, 71, 72, 73, 74], [1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229], [75, 76, 77, 78, 79], [1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304], [80, 81, 82, 83, 84], [1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379], [85, 86, 87, 88, 89], [1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454], [90, 91, 92, 93, 94], [1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529], [95, 96, 97, 98, 99], [1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604], [100, 101, 102, 103, 104], [1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679]]\n",
            "(750, 1680)\n",
            "(750,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating binary classification model 1680\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Activation, Dense, Conv1D, Dropout, MaxPooling1D, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy, binary_crossentropy\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        " \n",
        "model = Sequential([\n",
        "    Conv1D(filters=32, kernel_size=4, input_shape=(1680,1), padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(pool_size=4, strides=4), #max wert der 3 stellen und dann 3 stellen weiter wandern\n",
        "    Conv1D(filters=64, kernel_size=21, padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(pool_size=21, strides=21),\n",
        "    LSTM(20, activation='tanh'),\n",
        "    Dropout(0.3),\n",
        "    Dense(units=1, activation='sigmoid') #sigmoid\n",
        "])\n",
        "\n",
        "\n",
        "save_callback = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    min_delta=0,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "def scheduler(epoche, lr):\n",
        "      if epoche < 2:\n",
        "          return lr\n",
        "      else:\n",
        "          return lr*0.97\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k27rtxVFTZzG",
        "outputId": "1808afe9-25aa-4bbf-a648-4df92c58475a"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_30 (Conv1D)          (None, 1680, 32)          160       \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 1680, 32)          0         \n",
            "                                                                 \n",
            " max_pooling1d_30 (MaxPoolin  (None, 420, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_31 (Conv1D)          (None, 420, 64)           43072     \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 420, 64)           0         \n",
            "                                                                 \n",
            " max_pooling1d_31 (MaxPoolin  (None, 20, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 20)                6800      \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,053\n",
            "Trainable params: 50,053\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import json files 1575\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "PATH = \"/content.gdrive/MyDrive/Datasets_1575\"\n",
        "sets = []\n",
        "try:\n",
        "    sets = next(os.walk(PATH))[2]\n",
        "except StopIteration:\n",
        "    pass\n",
        "\n",
        "print(sets)\n",
        "X = np.empty(shape=(0,1575))\n",
        "y = np.empty(shape=0)\n",
        "\n",
        "\n",
        "\n",
        "for path in sets:\n",
        "    path = PATH + '/' + path\n",
        "    with open(path, \"r\") as fp:\n",
        "        data1 = json.load(fp)\n",
        "\n",
        "    # convert lists to numpy arrays\n",
        "    X1 = np.array(data1[\"keypoints\"])\n",
        "    #X = np.array(data[\"mfcc\"])\n",
        "    y1 = np.array(data1[\"labels\"])\n",
        "\n",
        "    X = np.concatenate((X,X1), axis=0)\n",
        "    y = np.concatenate((y,y1), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyMFNnOcDe-N",
        "outputId": "f38da2aa-8013-4bfd-844e-d4e0ec1325a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data_manually_labeled_original.json', 'data_manually_labled_Telemark_mirror.json', 'data_Manually_Labeled_09042022.json', 'data_Manually_Labeled_mirror_09042022.json', 'data_Manually_Labeled_11042022.json']\n",
            "(1082, 1575)\n",
            "(1082,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating binary classification model 1575\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Activation, Dense, Conv1D, Dropout, MaxPooling1D, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy, binary_crossentropy\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(filters=32, kernel_size=3, input_shape=(1575,1), padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(pool_size=3, strides=3), #max wert der 3 stellen und dann 3 stellen weiter wandern\n",
        "    Conv1D(filters=64, kernel_size=25, padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(pool_size=25, strides=25),\n",
        "    LSTM(21, activation='tanh'),\n",
        "    Dropout(0.3),\n",
        "    Dense(units=1, activation='sigmoid') #sigmoid\n",
        "])\n",
        "\"\"\"\n",
        "model = Sequential([\n",
        "    Conv1D(filters=32, kernel_size=3, input_shape=(1575,1), padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(), #max wert der 2 stellen und dann 2 stellen weiter wandern (stides = pool Size default)\n",
        "    Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(),\n",
        "    Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(),\n",
        "    Conv1D(filters=256, kernel_size=3, padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(), \n",
        "    Conv1D(filters=512, kernel_size=3, padding='same', activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    MaxPooling1D(),        \n",
        "    LSTM(21, activation='tanh'),\n",
        "    Dropout(0.3),\n",
        "    Dense(units=1, activation='sigmoid') #sigmoid\n",
        "])\n",
        "\"\"\"\n",
        "save_callback = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    min_delta=0,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "def scheduler(epoche, lr):\n",
        "      if epoche < 2:\n",
        "          return lr\n",
        "      else:\n",
        "          return lr*0.97\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--kNWO0HJohG",
        "outputId": "0374967d-5696-4578-ac70-e21d41e2cb61"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_18 (Conv1D)          (None, 1575, 32)          128       \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 1575, 32)          0         \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 525, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 525, 64)           51264     \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 525, 64)           0         \n",
            "                                                                 \n",
            " max_pooling1d_19 (MaxPoolin  (None, 21, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 21)                7224      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 21)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,638\n",
            "Trainable params: 58,638\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=X, y=y, batch_size=40, validation_split = 0.2, epochs=1000, shuffle=True, verbose = 2, callbacks=[save_callback, lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-TUyZBBLCw7",
        "outputId": "c5f445e5-0ca2-4149-a975-ea87bb77471a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/1000\n",
            "22/22 - 8s - loss: 0.7097 - accuracy: 0.4936 - val_loss: 0.7517 - val_accuracy: 0.2258 - lr: 0.0010 - 8s/epoch - 349ms/step\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/1000\n",
            "22/22 - 5s - loss: 0.6935 - accuracy: 0.5457 - val_loss: 0.7070 - val_accuracy: 0.3364 - lr: 0.0010 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0009700000460725278.\n",
            "Epoch 3/1000\n",
            "22/22 - 5s - loss: 0.6973 - accuracy: 0.5225 - val_loss: 0.7177 - val_accuracy: 0.2811 - lr: 9.7000e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.000940900050336495.\n",
            "Epoch 4/1000\n",
            "22/22 - 5s - loss: 0.7018 - accuracy: 0.4925 - val_loss: 0.7276 - val_accuracy: 0.2442 - lr: 9.4090e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.000912673061247915.\n",
            "Epoch 5/1000\n",
            "22/22 - 5s - loss: 0.6919 - accuracy: 0.5353 - val_loss: 0.7182 - val_accuracy: 0.2396 - lr: 9.1267e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0008852928807027637.\n",
            "Epoch 6/1000\n",
            "22/22 - 5s - loss: 0.6929 - accuracy: 0.5283 - val_loss: 0.6907 - val_accuracy: 0.6083 - lr: 8.8529e-04 - 5s/epoch - 231ms/step\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0008587341010570526.\n",
            "Epoch 7/1000\n",
            "22/22 - 5s - loss: 0.6879 - accuracy: 0.5445 - val_loss: 0.6961 - val_accuracy: 0.3687 - lr: 8.5873e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0008329721051268279.\n",
            "Epoch 8/1000\n",
            "22/22 - 5s - loss: 0.6927 - accuracy: 0.5295 - val_loss: 0.6773 - val_accuracy: 0.7465 - lr: 8.3297e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0008079829532653093.\n",
            "Epoch 9/1000\n",
            "22/22 - 5s - loss: 0.6914 - accuracy: 0.5329 - val_loss: 0.7114 - val_accuracy: 0.2166 - lr: 8.0798e-04 - 5s/epoch - 248ms/step\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0007837434398243203.\n",
            "Epoch 10/1000\n",
            "22/22 - 5s - loss: 0.6891 - accuracy: 0.5341 - val_loss: 0.6906 - val_accuracy: 0.5899 - lr: 7.8374e-04 - 5s/epoch - 248ms/step\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0007602311496157199.\n",
            "Epoch 11/1000\n",
            "22/22 - 5s - loss: 0.6872 - accuracy: 0.5734 - val_loss: 0.6950 - val_accuracy: 0.4654 - lr: 7.6023e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0007374242320656776.\n",
            "Epoch 12/1000\n",
            "22/22 - 5s - loss: 0.6865 - accuracy: 0.5376 - val_loss: 0.6954 - val_accuracy: 0.4608 - lr: 7.3742e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0007153015141375363.\n",
            "Epoch 13/1000\n",
            "22/22 - 5s - loss: 0.6858 - accuracy: 0.5422 - val_loss: 0.6685 - val_accuracy: 0.7189 - lr: 7.1530e-04 - 5s/epoch - 232ms/step\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0006938424438703805.\n",
            "Epoch 14/1000\n",
            "22/22 - 5s - loss: 0.6841 - accuracy: 0.5688 - val_loss: 0.6731 - val_accuracy: 0.6866 - lr: 6.9384e-04 - 5s/epoch - 234ms/step\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.000673027146840468.\n",
            "Epoch 15/1000\n",
            "22/22 - 5s - loss: 0.6705 - accuracy: 0.6012 - val_loss: 0.6898 - val_accuracy: 0.5207 - lr: 6.7303e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0006528363132383674.\n",
            "Epoch 16/1000\n",
            "22/22 - 5s - loss: 0.6778 - accuracy: 0.5526 - val_loss: 0.6722 - val_accuracy: 0.6359 - lr: 6.5284e-04 - 5s/epoch - 231ms/step\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0006332511978689581.\n",
            "Epoch 17/1000\n",
            "22/22 - 5s - loss: 0.6727 - accuracy: 0.6012 - val_loss: 0.6286 - val_accuracy: 0.7327 - lr: 6.3325e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0006142536766128615.\n",
            "Epoch 18/1000\n",
            "22/22 - 5s - loss: 0.6771 - accuracy: 0.5908 - val_loss: 0.6674 - val_accuracy: 0.6359 - lr: 6.1425e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0005958260770421475.\n",
            "Epoch 19/1000\n",
            "22/22 - 5s - loss: 0.6635 - accuracy: 0.6081 - val_loss: 0.6340 - val_accuracy: 0.7097 - lr: 5.9583e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0005779512913431972.\n",
            "Epoch 20/1000\n",
            "22/22 - 5s - loss: 0.6626 - accuracy: 0.6173 - val_loss: 0.6917 - val_accuracy: 0.4747 - lr: 5.7795e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0005606127763167024.\n",
            "Epoch 21/1000\n",
            "22/22 - 5s - loss: 0.6708 - accuracy: 0.5954 - val_loss: 0.6621 - val_accuracy: 0.6083 - lr: 5.6061e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0005437943839933723.\n",
            "Epoch 22/1000\n",
            "22/22 - 5s - loss: 0.6488 - accuracy: 0.6382 - val_loss: 0.6294 - val_accuracy: 0.6959 - lr: 5.4379e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0005274805310182273.\n",
            "Epoch 23/1000\n",
            "22/22 - 5s - loss: 0.6358 - accuracy: 0.6497 - val_loss: 0.5950 - val_accuracy: 0.6912 - lr: 5.2748e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0005116561421891674.\n",
            "Epoch 24/1000\n",
            "22/22 - 5s - loss: 0.6290 - accuracy: 0.6474 - val_loss: 0.6099 - val_accuracy: 0.7143 - lr: 5.1166e-04 - 5s/epoch - 230ms/step\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0004963064810726792.\n",
            "Epoch 25/1000\n",
            "22/22 - 5s - loss: 0.6210 - accuracy: 0.6543 - val_loss: 0.5964 - val_accuracy: 0.6912 - lr: 4.9631e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0004814172629266977.\n",
            "Epoch 26/1000\n",
            "22/22 - 5s - loss: 0.6226 - accuracy: 0.6566 - val_loss: 0.5791 - val_accuracy: 0.7189 - lr: 4.8142e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00046697473939275367.\n",
            "Epoch 27/1000\n",
            "22/22 - 5s - loss: 0.6241 - accuracy: 0.6705 - val_loss: 0.5608 - val_accuracy: 0.7327 - lr: 4.6697e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0004529655008809641.\n",
            "Epoch 28/1000\n",
            "22/22 - 5s - loss: 0.6107 - accuracy: 0.6636 - val_loss: 0.5918 - val_accuracy: 0.7097 - lr: 4.5297e-04 - 5s/epoch - 231ms/step\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0004393765330314636.\n",
            "Epoch 29/1000\n",
            "22/22 - 5s - loss: 0.6125 - accuracy: 0.6809 - val_loss: 0.5653 - val_accuracy: 0.7097 - lr: 4.3938e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00042619524494512005.\n",
            "Epoch 30/1000\n",
            "22/22 - 5s - loss: 0.5841 - accuracy: 0.7098 - val_loss: 0.5572 - val_accuracy: 0.7143 - lr: 4.2620e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.00041340938449138773.\n",
            "Epoch 31/1000\n",
            "22/22 - 5s - loss: 0.5851 - accuracy: 0.6983 - val_loss: 0.5403 - val_accuracy: 0.7373 - lr: 4.1341e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0004010070947697386.\n",
            "Epoch 32/1000\n",
            "22/22 - 5s - loss: 0.5733 - accuracy: 0.7121 - val_loss: 0.5410 - val_accuracy: 0.7327 - lr: 4.0101e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0003889768858789466.\n",
            "Epoch 33/1000\n",
            "22/22 - 5s - loss: 0.5595 - accuracy: 0.7283 - val_loss: 0.5454 - val_accuracy: 0.7281 - lr: 3.8898e-04 - 5s/epoch - 230ms/step\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.00037730757845565676.\n",
            "Epoch 34/1000\n",
            "22/22 - 5s - loss: 0.5862 - accuracy: 0.6948 - val_loss: 0.5432 - val_accuracy: 0.7327 - lr: 3.7731e-04 - 5s/epoch - 229ms/step\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.000365988360135816.\n",
            "Epoch 35/1000\n",
            "22/22 - 5s - loss: 0.6078 - accuracy: 0.6775 - val_loss: 0.5579 - val_accuracy: 0.7235 - lr: 3.6599e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0003550087008625269.\n",
            "Epoch 36/1000\n",
            "22/22 - 5s - loss: 0.5681 - accuracy: 0.7075 - val_loss: 0.5233 - val_accuracy: 0.7465 - lr: 3.5501e-04 - 5s/epoch - 231ms/step\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.00034435843757819385.\n",
            "Epoch 37/1000\n",
            "22/22 - 5s - loss: 0.5844 - accuracy: 0.6936 - val_loss: 0.5446 - val_accuracy: 0.7189 - lr: 3.4436e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0003340276895323768.\n",
            "Epoch 38/1000\n",
            "22/22 - 5s - loss: 0.5658 - accuracy: 0.7179 - val_loss: 0.5474 - val_accuracy: 0.7327 - lr: 3.3403e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0003240068582817912.\n",
            "Epoch 39/1000\n",
            "22/22 - 5s - loss: 0.5710 - accuracy: 0.6983 - val_loss: 0.5332 - val_accuracy: 0.7419 - lr: 3.2401e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0003142866559210233.\n",
            "Epoch 40/1000\n",
            "22/22 - 5s - loss: 0.5469 - accuracy: 0.7399 - val_loss: 0.5263 - val_accuracy: 0.7419 - lr: 3.1429e-04 - 5s/epoch - 225ms/step\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0003048580486210994.\n",
            "Epoch 41/1000\n",
            "22/22 - 5s - loss: 0.5302 - accuracy: 0.7410 - val_loss: 0.5208 - val_accuracy: 0.7465 - lr: 3.0486e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0002957123130909167.\n",
            "Epoch 42/1000\n",
            "22/22 - 5s - loss: 0.5484 - accuracy: 0.7283 - val_loss: 0.5169 - val_accuracy: 0.7465 - lr: 2.9571e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.00028684095188509674.\n",
            "Epoch 43/1000\n",
            "22/22 - 5s - loss: 0.5390 - accuracy: 0.7353 - val_loss: 0.5181 - val_accuracy: 0.7512 - lr: 2.8684e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0002782357216347009.\n",
            "Epoch 44/1000\n",
            "22/22 - 5s - loss: 0.5495 - accuracy: 0.7260 - val_loss: 0.5148 - val_accuracy: 0.7512 - lr: 2.7824e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.00026988866127794606.\n",
            "Epoch 45/1000\n",
            "22/22 - 5s - loss: 0.5646 - accuracy: 0.7249 - val_loss: 0.5199 - val_accuracy: 0.7465 - lr: 2.6989e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.00026179200736805794.\n",
            "Epoch 46/1000\n",
            "22/22 - 5s - loss: 0.5384 - accuracy: 0.7445 - val_loss: 0.5129 - val_accuracy: 0.7512 - lr: 2.6179e-04 - 5s/epoch - 235ms/step\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0002539382505347021.\n",
            "Epoch 47/1000\n",
            "22/22 - 5s - loss: 0.5283 - accuracy: 0.7410 - val_loss: 0.5149 - val_accuracy: 0.7512 - lr: 2.5394e-04 - 5s/epoch - 231ms/step\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.00024632010725326835.\n",
            "Epoch 48/1000\n",
            "22/22 - 5s - loss: 0.5209 - accuracy: 0.7480 - val_loss: 0.5126 - val_accuracy: 0.7558 - lr: 2.4632e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.00023893049161415546.\n",
            "Epoch 49/1000\n",
            "22/22 - 5s - loss: 0.5107 - accuracy: 0.7480 - val_loss: 0.5109 - val_accuracy: 0.7558 - lr: 2.3893e-04 - 5s/epoch - 232ms/step\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.000231762571784202.\n",
            "Epoch 50/1000\n",
            "22/22 - 5s - loss: 0.5099 - accuracy: 0.7526 - val_loss: 0.5117 - val_accuracy: 0.7512 - lr: 2.3176e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0002248096994298976.\n",
            "Epoch 51/1000\n",
            "22/22 - 5s - loss: 0.5000 - accuracy: 0.7688 - val_loss: 0.5158 - val_accuracy: 0.7419 - lr: 2.2481e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00021806540971738286.\n",
            "Epoch 52/1000\n",
            "22/22 - 5s - loss: 0.4914 - accuracy: 0.7688 - val_loss: 0.5144 - val_accuracy: 0.7512 - lr: 2.1807e-04 - 5s/epoch - 225ms/step\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.00021152344954316504.\n",
            "Epoch 53/1000\n",
            "22/22 - 5s - loss: 0.4839 - accuracy: 0.7711 - val_loss: 0.5110 - val_accuracy: 0.7512 - lr: 2.1152e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00020517774930340238.\n",
            "Epoch 54/1000\n",
            "22/22 - 5s - loss: 0.4959 - accuracy: 0.7757 - val_loss: 0.5121 - val_accuracy: 0.7512 - lr: 2.0518e-04 - 5s/epoch - 230ms/step\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00019902242289390415.\n",
            "Epoch 55/1000\n",
            "22/22 - 5s - loss: 0.4991 - accuracy: 0.7734 - val_loss: 0.5106 - val_accuracy: 0.7512 - lr: 1.9902e-04 - 5s/epoch - 230ms/step\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0001930517535947729.\n",
            "Epoch 56/1000\n",
            "22/22 - 5s - loss: 0.4854 - accuracy: 0.7838 - val_loss: 0.5132 - val_accuracy: 0.7512 - lr: 1.9305e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.00018726019407040438.\n",
            "Epoch 57/1000\n",
            "22/22 - 5s - loss: 0.4884 - accuracy: 0.7653 - val_loss: 0.5095 - val_accuracy: 0.7512 - lr: 1.8726e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.00018164239460020327.\n",
            "Epoch 58/1000\n",
            "22/22 - 5s - loss: 0.4921 - accuracy: 0.7642 - val_loss: 0.5063 - val_accuracy: 0.7558 - lr: 1.8164e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.00017619311838643626.\n",
            "Epoch 59/1000\n",
            "22/22 - 5s - loss: 0.4773 - accuracy: 0.7815 - val_loss: 0.5085 - val_accuracy: 0.7512 - lr: 1.7619e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.00017090732624637893.\n",
            "Epoch 60/1000\n",
            "22/22 - 5s - loss: 0.4751 - accuracy: 0.7965 - val_loss: 0.5122 - val_accuracy: 0.7512 - lr: 1.7091e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00016578010603552685.\n",
            "Epoch 61/1000\n",
            "22/22 - 5s - loss: 0.4657 - accuracy: 0.7850 - val_loss: 0.5108 - val_accuracy: 0.7512 - lr: 1.6578e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.00016080670087831095.\n",
            "Epoch 62/1000\n",
            "22/22 - 5s - loss: 0.4472 - accuracy: 0.8139 - val_loss: 0.5098 - val_accuracy: 0.7512 - lr: 1.6081e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00015598249505273997.\n",
            "Epoch 63/1000\n",
            "22/22 - 5s - loss: 0.4566 - accuracy: 0.7838 - val_loss: 0.5174 - val_accuracy: 0.7834 - lr: 1.5598e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00015130301399040035.\n",
            "Epoch 64/1000\n",
            "22/22 - 5s - loss: 0.4589 - accuracy: 0.7792 - val_loss: 0.5174 - val_accuracy: 0.7512 - lr: 1.5130e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00014676392427645624.\n",
            "Epoch 65/1000\n",
            "22/22 - 5s - loss: 0.4751 - accuracy: 0.7838 - val_loss: 0.5036 - val_accuracy: 0.7512 - lr: 1.4676e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.0001423610054189339.\n",
            "Epoch 66/1000\n",
            "22/22 - 5s - loss: 0.4468 - accuracy: 0.8046 - val_loss: 0.5138 - val_accuracy: 0.7512 - lr: 1.4236e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.00013809017807943745.\n",
            "Epoch 67/1000\n",
            "22/22 - 5s - loss: 0.4553 - accuracy: 0.7988 - val_loss: 0.5057 - val_accuracy: 0.7512 - lr: 1.3809e-04 - 5s/epoch - 225ms/step\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00013394747584243304.\n",
            "Epoch 68/1000\n",
            "22/22 - 5s - loss: 0.4659 - accuracy: 0.7873 - val_loss: 0.5129 - val_accuracy: 0.7512 - lr: 1.3395e-04 - 5s/epoch - 225ms/step\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00012992904521524906.\n",
            "Epoch 69/1000\n",
            "22/22 - 5s - loss: 0.4301 - accuracy: 0.8162 - val_loss: 0.5114 - val_accuracy: 0.7512 - lr: 1.2993e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0001260311738587916.\n",
            "Epoch 70/1000\n",
            "22/22 - 5s - loss: 0.4370 - accuracy: 0.8208 - val_loss: 0.5064 - val_accuracy: 0.7465 - lr: 1.2603e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.00012225023412611334.\n",
            "Epoch 71/1000\n",
            "22/22 - 5s - loss: 0.4348 - accuracy: 0.8069 - val_loss: 0.5096 - val_accuracy: 0.7512 - lr: 1.2225e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.00011858272540848702.\n",
            "Epoch 72/1000\n",
            "22/22 - 5s - loss: 0.4295 - accuracy: 0.8104 - val_loss: 0.5144 - val_accuracy: 0.7512 - lr: 1.1858e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.00011502524590468965.\n",
            "Epoch 73/1000\n",
            "22/22 - 5s - loss: 0.4281 - accuracy: 0.8104 - val_loss: 0.5162 - val_accuracy: 0.7512 - lr: 1.1503e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.00011157448556332383.\n",
            "Epoch 74/1000\n",
            "22/22 - 5s - loss: 0.4251 - accuracy: 0.8081 - val_loss: 0.5185 - val_accuracy: 0.7512 - lr: 1.1157e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.0001082272543135332.\n",
            "Epoch 75/1000\n",
            "22/22 - 5s - loss: 0.4393 - accuracy: 0.8081 - val_loss: 0.5086 - val_accuracy: 0.7465 - lr: 1.0823e-04 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.00010498043971892912.\n",
            "Epoch 76/1000\n",
            "22/22 - 5s - loss: 0.4177 - accuracy: 0.8301 - val_loss: 0.5027 - val_accuracy: 0.7512 - lr: 1.0498e-04 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.00010183102815062739.\n",
            "Epoch 77/1000\n",
            "22/22 - 5s - loss: 0.4671 - accuracy: 0.7942 - val_loss: 0.4961 - val_accuracy: 0.7512 - lr: 1.0183e-04 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 9.87760977295693e-05.\n",
            "Epoch 78/1000\n",
            "22/22 - 5s - loss: 0.4436 - accuracy: 0.7919 - val_loss: 0.5009 - val_accuracy: 0.7512 - lr: 9.8776e-05 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 9.581281832652167e-05.\n",
            "Epoch 79/1000\n",
            "22/22 - 5s - loss: 0.4318 - accuracy: 0.8173 - val_loss: 0.5063 - val_accuracy: 0.7465 - lr: 9.5813e-05 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 9.293843038904015e-05.\n",
            "Epoch 80/1000\n",
            "22/22 - 5s - loss: 0.4122 - accuracy: 0.8347 - val_loss: 0.5092 - val_accuracy: 0.7465 - lr: 9.2938e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 9.015028022986371e-05.\n",
            "Epoch 81/1000\n",
            "22/22 - 5s - loss: 0.4277 - accuracy: 0.8139 - val_loss: 0.5086 - val_accuracy: 0.7465 - lr: 9.0150e-05 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.744577062316238e-05.\n",
            "Epoch 82/1000\n",
            "22/22 - 5s - loss: 0.4203 - accuracy: 0.8139 - val_loss: 0.5114 - val_accuracy: 0.7512 - lr: 8.7446e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 8.482239609293174e-05.\n",
            "Epoch 83/1000\n",
            "22/22 - 5s - loss: 0.4157 - accuracy: 0.8127 - val_loss: 0.5131 - val_accuracy: 0.7465 - lr: 8.4822e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 8.227772173995617e-05.\n",
            "Epoch 84/1000\n",
            "22/22 - 5s - loss: 0.4208 - accuracy: 0.8220 - val_loss: 0.5108 - val_accuracy: 0.7512 - lr: 8.2278e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 7.980939029948786e-05.\n",
            "Epoch 85/1000\n",
            "22/22 - 5s - loss: 0.4007 - accuracy: 0.8312 - val_loss: 0.5096 - val_accuracy: 0.7465 - lr: 7.9809e-05 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 7.741510802588891e-05.\n",
            "Epoch 86/1000\n",
            "22/22 - 5s - loss: 0.4139 - accuracy: 0.8220 - val_loss: 0.5118 - val_accuracy: 0.7465 - lr: 7.7415e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 7.509265175031032e-05.\n",
            "Epoch 87/1000\n",
            "22/22 - 5s - loss: 0.4057 - accuracy: 0.8509 - val_loss: 0.5153 - val_accuracy: 0.7512 - lr: 7.5093e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 7.283986888069194e-05.\n",
            "Epoch 88/1000\n",
            "22/22 - 5s - loss: 0.4098 - accuracy: 0.8185 - val_loss: 0.5125 - val_accuracy: 0.7512 - lr: 7.2840e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 7.065467034408356e-05.\n",
            "Epoch 89/1000\n",
            "22/22 - 5s - loss: 0.4091 - accuracy: 0.8162 - val_loss: 0.5100 - val_accuracy: 0.7465 - lr: 7.0655e-05 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 6.8535030586645e-05.\n",
            "Epoch 90/1000\n",
            "22/22 - 5s - loss: 0.4052 - accuracy: 0.8335 - val_loss: 0.5055 - val_accuracy: 0.7465 - lr: 6.8535e-05 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 6.647898051596712e-05.\n",
            "Epoch 91/1000\n",
            "22/22 - 5s - loss: 0.4280 - accuracy: 0.8046 - val_loss: 0.5075 - val_accuracy: 0.7465 - lr: 6.6479e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 6.448461455875076e-05.\n",
            "Epoch 92/1000\n",
            "22/22 - 5s - loss: 0.4257 - accuracy: 0.8197 - val_loss: 0.5082 - val_accuracy: 0.7512 - lr: 6.4485e-05 - 5s/epoch - 231ms/step\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 6.255007654544898e-05.\n",
            "Epoch 93/1000\n",
            "22/22 - 5s - loss: 0.3971 - accuracy: 0.8416 - val_loss: 0.5114 - val_accuracy: 0.7465 - lr: 6.2550e-05 - 5s/epoch - 229ms/step\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 6.067357382562477e-05.\n",
            "Epoch 94/1000\n",
            "22/22 - 5s - loss: 0.3976 - accuracy: 0.8324 - val_loss: 0.5115 - val_accuracy: 0.7465 - lr: 6.0674e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 5.885336668143282e-05.\n",
            "Epoch 95/1000\n",
            "22/22 - 5s - loss: 0.4080 - accuracy: 0.8358 - val_loss: 0.5127 - val_accuracy: 0.7465 - lr: 5.8853e-05 - 5s/epoch - 233ms/step\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 5.708776479877997e-05.\n",
            "Epoch 96/1000\n",
            "22/22 - 5s - loss: 0.4039 - accuracy: 0.8301 - val_loss: 0.5181 - val_accuracy: 0.7512 - lr: 5.7088e-05 - 5s/epoch - 228ms/step\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 5.5375130796164736e-05.\n",
            "Epoch 97/1000\n",
            "22/22 - 5s - loss: 0.4117 - accuracy: 0.8092 - val_loss: 0.5177 - val_accuracy: 0.7834 - lr: 5.5375e-05 - 5s/epoch - 229ms/step\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 5.3713876695837826e-05.\n",
            "Epoch 98/1000\n",
            "22/22 - 5s - loss: 0.3831 - accuracy: 0.8347 - val_loss: 0.5073 - val_accuracy: 0.7465 - lr: 5.3714e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 5.210246039496269e-05.\n",
            "Epoch 99/1000\n",
            "22/22 - 5s - loss: 0.3956 - accuracy: 0.8277 - val_loss: 0.5195 - val_accuracy: 0.7512 - lr: 5.2102e-05 - 5s/epoch - 230ms/step\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 5.053938566561555e-05.\n",
            "Epoch 100/1000\n",
            "22/22 - 5s - loss: 0.3933 - accuracy: 0.8428 - val_loss: 0.5125 - val_accuracy: 0.7465 - lr: 5.0539e-05 - 5s/epoch - 234ms/step\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 4.902320568362484e-05.\n",
            "Epoch 101/1000\n",
            "22/22 - 5s - loss: 0.3862 - accuracy: 0.8370 - val_loss: 0.5172 - val_accuracy: 0.7512 - lr: 4.9023e-05 - 5s/epoch - 229ms/step\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 4.7552508913213384e-05.\n",
            "Epoch 102/1000\n",
            "22/22 - 5s - loss: 0.3946 - accuracy: 0.8301 - val_loss: 0.5223 - val_accuracy: 0.7512 - lr: 4.7553e-05 - 5s/epoch - 230ms/step\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 4.6125933222356254e-05.\n",
            "Epoch 103/1000\n",
            "22/22 - 5s - loss: 0.3702 - accuracy: 0.8486 - val_loss: 0.5192 - val_accuracy: 0.7512 - lr: 4.6126e-05 - 5s/epoch - 231ms/step\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 4.4742155296262354e-05.\n",
            "Epoch 104/1000\n",
            "22/22 - 5s - loss: 0.3923 - accuracy: 0.8312 - val_loss: 0.5222 - val_accuracy: 0.7512 - lr: 4.4742e-05 - 5s/epoch - 226ms/step\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 4.339989063737448e-05.\n",
            "Epoch 105/1000\n",
            "22/22 - 5s - loss: 0.4106 - accuracy: 0.8266 - val_loss: 0.5118 - val_accuracy: 0.7465 - lr: 4.3400e-05 - 5s/epoch - 234ms/step\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 4.20978935653693e-05.\n",
            "Epoch 106/1000\n",
            "22/22 - 5s - loss: 0.3959 - accuracy: 0.8347 - val_loss: 0.5148 - val_accuracy: 0.7512 - lr: 4.2098e-05 - 5s/epoch - 232ms/step\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 4.0834957217157354e-05.\n",
            "Epoch 107/1000\n",
            "22/22 - 5s - loss: 0.4060 - accuracy: 0.8104 - val_loss: 0.5210 - val_accuracy: 0.7512 - lr: 4.0835e-05 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 3.960991001804359e-05.\n",
            "Epoch 108/1000\n",
            "22/22 - 5s - loss: 0.3922 - accuracy: 0.8197 - val_loss: 0.5195 - val_accuracy: 0.7834 - lr: 3.9610e-05 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 3.8421612152887974e-05.\n",
            "Epoch 109/1000\n",
            "22/22 - 5s - loss: 0.3767 - accuracy: 0.8486 - val_loss: 0.5147 - val_accuracy: 0.7465 - lr: 3.8422e-05 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 3.726896262378432e-05.\n",
            "Epoch 110/1000\n",
            "22/22 - 5s - loss: 0.3875 - accuracy: 0.8289 - val_loss: 0.5148 - val_accuracy: 0.7465 - lr: 3.7269e-05 - 5s/epoch - 229ms/step\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 3.6150892192381434e-05.\n",
            "Epoch 111/1000\n",
            "22/22 - 5s - loss: 0.4002 - accuracy: 0.8428 - val_loss: 0.5283 - val_accuracy: 0.7512 - lr: 3.6151e-05 - 5s/epoch - 230ms/step\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 3.5066366908722554e-05.\n",
            "Epoch 112/1000\n",
            "22/22 - 5s - loss: 0.3978 - accuracy: 0.8393 - val_loss: 0.5124 - val_accuracy: 0.7465 - lr: 3.5066e-05 - 5s/epoch - 227ms/step\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 3.4014377524727025e-05.\n",
            "Epoch 113/1000\n",
            "Restoring model weights from the end of the best epoch: 63.\n",
            "22/22 - 5s - loss: 0.3857 - accuracy: 0.8370 - val_loss: 0.5189 - val_accuracy: 0.7512 - lr: 3.4014e-05 - 5s/epoch - 228ms/step\n",
            "Epoch 113: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "BRJpQbN1G1sq",
        "outputId": "213bf4db-36f2-477d-85c1-3644c6247be3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gc1fW/36PVqnfJcrcl9967DdjYgGmmY3qAhECAUBIgpHwTQgiBJKRQf0BoIdTQQjEYXMG4yr1blpsk26qW1aUt9/fH3dXuSitpJXstS7rv8+iRZubOzN3FzGdOueeIUgqDwWAwdF5C2noCBoPBYGhbjBAYDAZDJ8cIgcFgMHRyjBAYDAZDJ8cIgcFgMHRyjBAYDAZDJ8cIgaFTISKvi8hjAY49ICJzgj0ng6GtMUJgMBgMnRwjBAZDO0REQtt6DoaOgxECw2mHyyXzoIhsEZEKEXlFRLqKyJciUiYii0Qk0Wv8PBHZLiIlIrJMRIZ6HRsrIhtc570HRNS710Uissl17koRGRXgHC8UkY0iUioi2SLySL3jM1zXK3Edv9m1P1JEnhKRgyJyXERWuPbNFJEcP9/DHNffj4jIByLyHxEpBW4WkUkissp1jyMi8qyIhHmdP1xEvhGRYhHJE5FfiUg3EakUkWSvceNEpEBErIF8dkPHwwiB4XTlCuAcYBBwMfAl8CugC/rf7T0AIjIIeAe4z3VsAfCZiIS5HoqfAG8CScB/XdfFde5Y4FXgdiAZeBH4VETCA5hfBXATkABcCPxERC51Xbeva77PuOY0BtjkOu+vwHhgmmtODwHOAL+TS4APXPd8C3AA9wMpwFRgNnCnaw6xwCLgK6AHMABYrJQ6CiwDrva67o3Au0opW4DzMHQwjBAYTleeUUrlKaVyge+ANUqpjUqpauBjYKxr3HzgC6XUN64H2V+BSPSDdgpgBf6hlLIppT4A1nnd48fAi0qpNUoph1LqDaDGdV6TKKWWKaW2KqWcSqktaDE6y3X4OmCRUuod132LlFKbRCQEuBW4VymV67rnSqVUTYDfySql1Ceue1YppdYrpVYrpexKqQNoIXPP4SLgqFLqKaVUtVKqTCm1xnXsDeAGABGxANeixdLQSTFCYDhdyfP6u8rPdozr7x7AQfcBpZQTyAZ6uo7lKt/Kige9/u4L/NzlWikRkRKgt+u8JhGRySKy1OVSOQ7cgX4zx3WNLD+npaBdU/6OBUJ2vTkMEpHPReSoy130eABzAPgfMExE0tFW13Gl1NpWzsnQATBCYGjvHEY/0AEQEUE/BHOBI0BP1z43fbz+zgb+qJRK8PqJUkq9E8B93wY+BXorpeKB/we475MN9PdzTiFQ3cixCiDK63NY0G4lb+qXCn4B2AUMVErFoV1n3nPo52/iLqvqfbRVcCPGGuj0GCEwtHfeBy4UkdmuYOfP0e6dlcAqwA7cIyJWEbkcmOR17svAHa63exGRaFcQODaA+8YCxUqpahGZhHYHuXkLmCMiV4tIqIgki8gYl7XyKvA3EekhIhYRmeqKSewBIlz3twK/AZqLVcQCpUC5iAwBfuJ17HOgu4jcJyLhIhIrIpO9jv8buBmYhxGCTo8RAkO7Rim1G/1m+wz6jfti4GKlVK1Sqha4HP3AK0bHEz7yOjcDuA14FjgG7HWNDYQ7gUdFpAz4LVqQ3Nc9BFyAFqVidKB4tOvwA8BWdKyiGHgSCFFKHXdd819oa6YC8Mki8sMDaAEqQ4vae15zKEO7fS4GjgKZwCyv49+jg9QblFLe7jJDJ0RMYxqDoXMiIkuAt5VS/2rruRjaFiMEBkMnREQmAt+gYxxlbT0fQ9tiXEMGQydDRN5ArzG4z4iAAYxFYDAYDJ0eYxEYDAZDJ6fdFa5KSUlRaWlpbT0Ng8FgaFesX7++UClVf20K0A6FIC0tjYyMjLaehsFgMLQrRKTRNGHjGjIYDIZOjhECg8Fg6OQYITAYDIZOTruLEfjDZrORk5NDdXV1W08lqERERNCrVy+sVtM/xGAwnDw6hBDk5OQQGxtLWloavoUmOw5KKYqKisjJySE9Pb2tp2MwGDoQHcI1VF1dTXJycocVAQARITk5ucNbPQaD4dTTIYQA6NAi4KYzfEaDwXDq6TBCYDAY2j/rDx5j/cFjbT2NTocRgpNASUkJzz//fIvPu+CCCygpKQnCjAyG9odSivvf28SD/93c1lMJiJxjldz27wzySlvnrlVK8auPt7J0V/5JnlnLMUJwEmhMCOx2e5PnLViwgISEhGBNy2BoV2Tml3OouJJ9hRXkllS19XSa5bmle/lmRx5PL85s1flZBeW8veYQj32xA6ezbYt/GiE4CTz88MNkZWUxZswYJk6cyBlnnMG8efMYNmwYAJdeeinjx49n+PDhvPTSS3XnpaWlUVhYyIEDBxg6dCi33XYbw4cP59xzz6Wq6vT/H8FgOJks2plX9/eKzIJWXSO7uJJnl2RSY3ec8Hw+3XyY6U8s4eONOdSv0pxXWs2H63OJDrPwfkY2OccqW3z9RTu1JZBVUMHyPZ7P++LyLKb+aTF/+nIn+wsrTuxDBEiHSB/15vefbWfH4dKTes1hPeL43cXDGz3+xBNPsG3bNjZt2sSyZcu48MIL2bZtW12a56uvvkpSUhJVVVVMnDiRK664guTkZJ9rZGZm8s477/Dyyy9z9dVX8+GHH3LDDTec1M9hMJzOLN6Zz/AecRSU1fBdZiHzJ/Zp8TX+vHA3n20+zLbcUp69biyhlta965ZW23j0s+2UVtm5/73NfLHlCH+8bCRd4yIA+Nd3+3AoxZs3T+LGV9by3NIs/nT5yBbdY9GOPIZ0i6Wk0sYrK/Yza0gqe/PLeOrrPaTGhfOv7/bz4vJ9jO6dwBkDUpg2IJnxfRMJD7W06jM1hbEIgsCkSZN8cv2ffvppRo8ezZQpU8jOziYzs6EpmZ6ezpgxYwAYP348Bw4cOFXTNRhOiI2HjrEt9/gJXaOovIYNh44xZ2hXZgxIYWVWkV93idOpqLU7/V6juKKWhduOMjA1hq+2H+UXH26lvMbOe+sO8YNX1/L8sr3YHf7PzThQzM4jnhfIZxZnUlRRy/t3TOU3Fw7lu8xCzv/nd6zMKqSkspa31hziolHdmdwvmfkTe/NfP1aB3eHk8y2Hqaxt6CIurqhlw6FjnDu8GzdN68uKvYXsOFzKrz7aRmSYhU/ums6qh8/mwfMGExoivLA8i+teXsO/VwanvXSHswiaenM/VURHR9f9vWzZMhYtWsSqVauIiopi5syZftcChIeH1/1tsViMa8jQLiivsXPL6+uIDgvl24dmYQkJLMXZ6VSs2FvIpPQkIqwWlu4uQCmYM7QrmfllfLQxlx1HShnRM97nvN99up3vswpZ/LOzGqRTf7Qhh1qHk2evG8fC7Uf52zd7+HRzLjaHomtcOMv3FPDVtqP85crRDO4WW3detc3Bza+to9bu5PeXDGdSehKvfX+Aq8f3ZkzvBMb0TmDm4FRufzODG19Zy/g+iVTWOvjJzP4A3DmrP++ty+bv32Ty16tGISLU2B3c+84mvtp+lHvOHsDPzh3sM9elu/JxKpgzNJU+SVE8s3gvP34zg5xjVTx5xUhSYvTz4K5ZA7hr1gDKqm2s2VfMkO6xBANjEZwEYmNjKSvz3/Hv+PHjJCYmEhUVxa5du1i9evUpnp3B0HIeX7CTG19Z0+y4N1YeoKTSRm5JVcDZL0op/u9/27jp1bXc+dYGbA4ni3fm0TUunBE945gxIAWAFXsLfc47WFTB22sPsa+ggu313L9KKd5ee4hxfRIY3C2Wn549gAfPG8xlY3vy4U+msvqXs3nuunHkHqvi4mdWsCfP8//rst0FlNfYSUuJ4pcfbWX+i6uJtFp44DzPw3tAagyf3DWdOUNTWXugmNlDUhnSLQ6A7vGR3DClLx9uyOHS575nya48bn19HV9tP0pqbDifbDrcIMaweFceqbHhjOgRT0JUGFdN6EXOsSompSVx1fjeDb6z2Agrc4Z1pVdiVEDfcUsxQnASSE5OZvr06YwYMYIHH3zQ59jcuXOx2+0MHTqUhx9+mClTprTRLA2GwCirtvHmqoN8l1nIsYraJse9/N0+zhiYQte4cP69unm3hVKKJ77axVtrDjFjQApLduVz37ub+HZPAbOHdkVESI2LYHDXWFZk+grBM0v2YgkRRHwDywBr9xezr6CCayfpuIKIcNesAfz5ytGM75uEiHDhqO58ee8ZiMBr3x+oO/ezLYdJjg7js5/O4M6Z/Sksr+G+cwbRJTbc5x6xEVZeuH48z143lsfrxQN+feFQ/nLlKArKarj19QxW7yvmqatG89DcIRwqrmTDIU+aeI3dwfLd+vOGuCyo28/qz5yhXXniipF1+04lHc411Fa8/fbbfveHh4fz5Zdf+j3mjgOkpKSwbdu2uv0PPPDASZ+foXNRXmMn0moJ2FXjzf82HabKprNu1h0o5tzh3fyOc1sDD5w7mGW7C/j7oj3sL6wgPSXa73iA55dl8eLyfdw4pS+PXjKcl77dx5++3AVoN4mbGQNTeHP1QaptDiKsFg4UVvDxxlx+MDWNzTklLN6Zz31zBtWNf3ddNrHhoVw4qnuTny01LoJLxvTgk425PHz+EEJDhMU787hqfG/CQy08NHcIN09Po0tMuN/zQ0KEi0b1aLDfEiJcNaE3F4/uwQfrc0hLjmbGwBTKqm385pMQPtmYy/i+iQCs2VdMRa3D5/P2TIjkXz+Y0OTcg4mxCAyGDkRxRS2Pfb6DcX/4ht98srVV13h33SEGpsYQHhrC2v3FfseUVtt4+bv9zB6SyujeCVw7qTehIcKbqxq3Cl7/fj9/Wbiby8b25PfzhiMi3H5Wf352ziCGdo9jWv+UurEzBqZQa3fyycZcau1Onlmyl9AQ4Y6Z/Zg9NJWtucfrFnIVldfwxdYjXDq2J1Fhzb/b3jQ1jSqbgw/X57BoZx7VNicXeQlIamxEq8u5RFgt3DClLzMG6s8SG2HlnGHd+HzL4bog9yebcomwhjB9QEpTlzqlGCEwGDoIC7Ye4cw/L+XV7/fTv0sM76zNZlVWUYuusTXnONtyS7lxal/G9klgTSNC8M6aQxyvstW9lafGRXD+yO78d3223yyZD9bn8MhnOzh3WFf+cuUoH/fHPbMH8uW9ZxBh9aRFTk5PoltcBA9/tJUxj37NxxtzuGFKX1JjI5gztCug000B/vbNHhxOxQ+m9Q3oM47oGc/YPgn8Z/VBPtt8mK5x4UxMSwrsC2oFl43twbFKG9/uKeCFZVl8tCGX6yf39fm8bY1xDRkMbcifvtzJ0ePV/POasSd8rb99s4ceCRE8e904+iRFce7fv+XXH29lQb2HbFO8s+4QEdYQLhnTk8LyWp5dkklZtY3YCN8eGJ9sOsy4PgmM7OXJ6rlpal8+23yYkY98TYhod0nPhEh6JETy/d5CZgxI4ZkAc/ujwkJZeP+ZrMoqYmVWIQeKKuuydAamxtA7KZJFO/MY0zuBd9Ye4qapaQxIDTyj5qapfbn/vc3sK6zghzPSg+qXP2NgF5Kiw3jks+3kHKvikjE9+NUFQ4N2v9ZghMBgaCPsDifvrs2mrNrGo/NGEB/V+oZDB4sq2Jtfzm8vGsagrvqB+MfLRnDjK2t5fuleJvdL5u21h1h/4BgKncHSPT6SGQNSmNY/maSYMOwOxf825nLRqB7ER1qZnJ7E00oXgps52OPP3ptfzs4jpfz2omE+c5jQN5FHLxnO0ePaZVNrd5JbUsWh4krOHdaNv80f3aLFUPGRVuaO6MbcEb4xChFh9pCuvLP2EKVVNuIjrdzvFS8IhAtGduexz3dSVFHr4xYKBlZLCBeP6s4bqw4yZ2gqf71qdKtiN8EkqEIgInOBfwIW4F9KqSfqHe8DvAEkuMY8rJRaEMw5GQynCxkHj3G8ygbA8swC5o1uGIT0xu5wurJmGj5E3OUK3G4T0G+il47pwdNL9sKSvSREWZk1OJXw0BCUgsz8Ml5YnsWzS/f6XMudeTO2TwKhIcKa/cU+QvD5lsOI0CAwKyLcNDUt8C/gBJgztCuvrzxAxsFjPHZpy0U0PNTCT2b2r7Mqgs1dswbQNT6CW6enY23laudgEjQhEBEL8BxwDpADrBORT5VSO7yG/QZ4Xyn1gogMAxYAacGak8FwOrF4Zx5hlhAiwyws25XfpBAopZj/0mpKKmv5y1WjGdcn0ef4oh15DOoaQ59k3zzz3148nMgwC1P6JXPe8G4NXESl1TY2HDxGVa3OEoqPstZlt0SFhTKqV7xPwFgpxWebDzM5Pamu3EJbMCk9idiIUHomRNYJV0v50Rn9+NEZ/U7yzPyTGhfBnTMHnJJ7tYZgWgSTgL1KqX0AIvIucAngLQQKiHP9HQ8cDuJ8ThtiYmIoLy9v62kY2pjFO/OZ0j+ZpCgry/YU4HSqRn3VGa46/ZFWC1e+sJIfzkjn5+cOJsJq4XiVjXUHirntzIYPtaToMP50+ahG5xAXYfV526/PpPRkXlmxj6paB5FhFnYeKSOroIJbprdtu9Sw0BD+88PJJMeEnXZulvZIMG2UnkC213aOa583jwA3iEgO2hr4qb8LiciPRSRDRDIKClpXldBgaEtsDievfb+/zn+eVVDOvsIK5gxNZdaQVIoratnSRL2eN1YeIC4ilOUPzeSaSX14+bv9/PpjvfZk+Z4C7E7lk5d+spicnoTNodiYrZvFfLblMJYQ4fwR/tcWnEpG904I2krbzkZbO6uuBV5XSvUCLgDeFJEGc1JKvaSUmqCUmtClS5dTPsnmePjhh3nuuefqth955BEee+wxZs+ezbhx4xg5ciT/+9//2nCGhrbmP6sP8vvPdnD7mxnU2nVJBYCzh6Ry5sAuhAgsaaREQ35pNV9tO8rVE3qTGhvB45eN5J6zB/Dhhhzez8hm8c48kqLDGNM70e/5J8L4tERCBJ74chevrtjPp5sOM31ACsmNLLgytE+C6RrKBbyLZvRy7fPmh8BcAKXUKhGJAFKA1rfs+fJhONq6hTSN0m0knP9Eo4fnz5/Pfffdx1133QXA+++/z8KFC7nnnnuIi4ujsLCQKVOmMG/ePNN3uBNSXFHL37/ZQ9/kKDbnHOfxBTvZcaSUId1i695ox/ZJZNnufH52TsPsl3fWZmN3Km6Y4smTv3fOINYdOMZv/7eN0JAQ5o7oFhQXSVyEld9cOIw3Vx/k0c+1V/e+OQNP+n0MbUswhWAdMFBE0tECcA1wXb0xh4DZwOsiMhSIANqd72fs2LHk5+dz+PBhCgoKSExMpFu3btx///18++23hISEkJubS15eHt26tb1JbTi1PPX1bipqHXz4kwm8vfYQr31/ABG4e5YneDhrcBf++vUeCspqfGrc2BxO3lpzkLMGdSHNq3SDJUT457VjuOCfKygsrwmKW8jNrTPSuXVGOjnHKtl1pIxZQ4J3L0PbEDQhUErZReRuYCE6NfRVpdR2EXkUyFBKfQr8HHhZRO5HB45vVvXL9LWUJt7cg8lVV13FBx98wNGjR5k/fz5vvfUWBQUFrF+/HqvVSlpamt/y04b2i9OpePX7/cwcnMqA1Bi/Y3YcLq1b8DSwayy/PH8oGw6VsDm7hNleqZ4zB6eyYdG7fP5dHDefPwMRwelUvLHyAPllNfzp8oarZlNjI3jhhnG8uDyLMwcF32XaKzGqY/nki/dDcRYMmHNq75u3HWrKoM/pU4AyqOsIXGsCFtTb91uvv3cA04M5h1PF/Pnzue222ygsLGT58uW8//77pKamYrVaWbp0KQcPBqehhKHt+MvXu3lhWRZfb8/j/Tum+h3zh893+Cx4CgsN4aUbx/P1jjxGe63KHZ5g519hT/HhyrVcsk+YP7E3767NZmvuccb1SWg0s2diWlJQyyN0aBY9Aru/hIcPgfUUpsJ+dh8cz4af7YTTxFXc1sHiDsPw4cMpKyujZ8+edO/eneuvv56MjAxGjhzJv//9b4YMGdLWUzScAEopnz64H67P4YVlWaSnRLP2QDEZBxrW5FmZVciqfUX89OyBPgueusZFcOOUvj7xItm/nBAUF8bspqishl9/vI3iilqeumo0/71jmkmRPNk4HbBvGThq4PCGU3ffqhLIzYCyI3DswKm7bzOYEhMnka1bPUHqlJQUVq1a5XecWUPQvlh/sJgnv9rNugPFDOsex/i+iby7Nptp/ZN54YbxzPzLUl5YlsUrN3vezJVS/OObTLrGhXPd5AAWPO1bCkBUdR5L7+jO5upujOoVH5T+tAbgyCaodvUIOLgS+k47Nfc98B0oV7vMQ6shqW3XY7gxFoHB4IfckireX5fNLa+t5YoXVrGvoIJbp6cTEx7KO2sP0SspkuevH0d8pJWbp6WzeFc+u456umatyipi7YFi7pw5oPmCb0pB1jLoPhqAsAPfMjEtyYhAMMnSwktsD/1APpX3DYuBiHg4tPLU3bcZjEVgMABvrjrA3xdl4lQKp1NRWq1LKXeJDefB8wZzy/S0ulr3VbUORKh7wP9gWl9e/DaLF5Zl8c9rxqKU4u+L9tAtLoL5Exu2HWxA8T44fgim36ODiPuWwpQ7gvVRDaDdQt1GQs8JsO1D7SoKOQXCu28ppM3Q4n8qBagZOowQKKU6fI7+iSZUGfyTX1rN4wt2MahrTF0Bst5JUZwxsAuDusY0+HcVGeb7wEiICuO6SX149fv9HKu0kRhlZd2BYzx6yfDAyj9nLdG/+58N+Tthy3tgr4XQsJPy+Qz1qCnXD+EpP4GuI2D9a5C/QwtDMDl2QIv+pNvBVgmZC6GiEKLbvkFNhxCCiIgIioqKSE5O7rBioJSiqKiIiIi2K/TVUfnn4kxsDif/vGasT65+S7hr1gCOVdrYk1fG5uwS+neJDswaAO0uSOgDSf2g/yzIeAVy1kFah0ioO/04uBKcNv1dJ7vWchxcFXwhcLuj+s+CKl2yg0OrYehFwb1vAHQIIejVqxc5OTl09DpEERER9OrVq62n0aHYV1DOu+uyuX5yn1aLAEBidBhPXT26bjtgC9Vh1wHE4ZfpVMK0M0AsLheCEYKgsG8pWMKhz1QIjYC4ntpfP/nHwb9vbA9IGQSOWj2HQ6uMEJwsrFYr6emnR/TdcBqStx2WPu4pPSIhMGgunPFznvo6m/DQEH569kkqm3A8F779M3LsAEz7KfSf3XSueO56qCnVb4kAkQnQc7x+ezz7NydnTgZfspbqLCFrpN7uMxUOfq/99sHyKDgdsG85DLlI3yM0XP93PuQ/s/BU0yGEwNCJKM+HnZ/qN2nQLpVBcyHElQBXUwbbP4HaCr2dux62/hfC42DQufptu6YMtfZFbBlvMLBmLoPOeNCnrAMHV8KRLS2f27H9kPEaoCAqBf5zBfSd4Xrja+QBc+A7fSz9LM++/rPg27/Aquf0fFtCcn+9Utb9QKsqgR2fgK2JVe0hFhh0nv4u3eRugOy1DcdarDDskub92mV5+i17wDkQ7lp17XTqeEhs18bdMPu/08INWrAHztEus6aoKYe9i/QDPbZr02OL90PBThhzrWdfnymw7QPtw49JhcxvoPdkiPNqvHNoNRze1PS147rrB7076Fxbqb/76lKoKNDpqm7BB+g7Fb7/p/63GuZljRbs1vMcMAcsrke0rQrW/QuGXw7x9Ys4nzhGCAztg+rjsPIZWPU82Cp8j3UbCbN+ox/E3/4VKgs9x0IjYPq9bE2/hTVHdP52WbWdFXvP49ba/3Bf6EfYj4eA8yX9P/D2j+GDWz253i1CYPS1MPNhiO0G69+Ab/8MX61o+rT0syDKa3XwkAv151j4q1bMAZ0JM+uX2gJa8Q9PvnxTLPwVTLgVhl0Kq56FXZ83Pvab38G0u2HqXRBer09wVQmsfBpWv6ADotFd4IwHILEvLPkj5LmssuGXa4snWfchJmc9LH4E9n9bb16hMO4mOPMh3wczgL1GC+93f9UPWmuUDgBPu0dbVt7UlGlhXfkMhFhh8AWeY+41BIse0S8BFfkQGqldRQPPgxV/00ITCF2GwKxf6/ks/zOUH/UcC4uFfl5C0GcafPcU5GRAv7Og5BAsewI2v6P//aUM0teqLoFlT0LZYf1iMPXOwObSAqS9ZaJMmDBBZWRktO0kspbA1/8Hty01mR2BcGAFfHwH/PCbhv8z+0MpvfR/6eOQt829U/8afjmc+aB+0IL+H3TpH+tWaar0M9k66G56DRhNUnQYyhrJK6uP8PiCnTi9/qlPSk/iF3OHMP7Qa7D49zD+Zv1wePc66DURrnpDv/22BEuY5+3XjcOmH0JNERHfMHWxtkI/6FrKrs/1w6TUVeh34Lkw85eQmNb4OVXH4Pt/wMa3QDm09TTtpzDuBw2/g9JcWP4k7PzMtaO+peP6kkdcCSOugNXPu6weIDFdi2TRXi9BF895USlw5gMw8iptDdSU6gf3+tfBaW/8XmlnwJQ7dRrotg+antfQeVqAugz2HHI64c9p+mWj73QtcDv+B1ve1+dFJsKM+2H0dU2nmO7/FpY8BkWZerv3FH2vrsP1tjXS444Cfb8n01wvHaLvZQmHSbdBj7HaKizYpcf2mgizfwfpZzR+/2YQkfVKqQl+jxkhaAXfPw3f/B88uA+ik9t2Lu2Bd6/XD6jz/wyTb294vKZcv6253lxVzjokZx3VcenYh8wjJiJcPxgGnw89xjQ8316r3UUxqSytHcItr63DahHOG94Np1Is2HqUucO78YdLRxBuDSFEhJhwL2N48aP6zQyB7qPgB5/ph3N7xVatXRKJaS0rbFaYqR/aQy9p/t917nrY83VDyynEogW1u6srmlL6AVlRoF1KbmEpz4dNb3tceNEpMOa6hhYGaDfJ1g90gLU+fadBv5keV9iRLbB7gfbJeyMh2jXYc7z/z7Nvmf4s/WZ5rpW3Xb+tD7808H8PDrv+txgR13x8CPTnKtit/w4Nh9HXQLwrIcTp0IIbFu3r7mslRghONt/+FZb8AX6+p3mfZEfDVq3/Zw508U1FITw1WL/RpZ0BN9dzOdiq4e2rtG84PBabw8kRWzTP2y/mA8eZdE2I5av7ziA2IrC385ZwFeYAACAASURBVBv+tYbM/DIuGNmdjzbkUlpt44FzB3PnzP6NZ/Eopd0C2Wtg/ltG3A0dkqaEwMQIWoPDpn877W07j1ONvRaenajdYWf/Rr85hjRTpWTL+/p7Gnwh7PkKKos9/nCHDf57s35jvOwlGD2fX7y3iSW787n/vEE8agnhN59s5bHPd/LklfoN81hFLd/szOPSMT0JC/W9984jpazYW8hDcwdz58wB/GLuEEqrbaTGNrP2QgTO+X0rvxSDof1jag21BreJGkwh+O5vzWcpnCzWvgzbPmp+XOZCXQqhtlI/wF+eqX30bquyslj7SDNe09tKwaa3tL/zzAe0/3nPV55j/7sb9nwJFz4Fo+cDsCmnhAl9k/jBtDSum9yH28/qz3uudozbco9z0TMreOiDLdz/3iYcTl9r9pUV+4m0Wrhuks5+ibBamhcBg8FgLIJWEWwhsNfoAGZ5nn+f+Mkkey0seFCnzQ2d50lX88fGtyCmG9y7GbZ/pIO0/7kCR5/pHEseR8qOf0ONqwG7064DXHnb4IK/ajGI6wU7P9e+4J2fwpZ34ayHYeKPACittrGvoILLxnjS4+6bM5Clu/J54L+bqax1kBQdxi3T03jt+wNEhVl48opRhIQI+WXVfLrpMNdM6k1ClAngGwwtwQhBawi2a6jCtUK6vPWtmwPCXguf3auzXcrzIGuxzif3R1keZH6ts0lCw3RQa/jlsP51Kr9+nJRD32MbeD7Ws3+ls1YWPKDTOi3hMPJK7X4ZciFseANKj8CCh/TxMx+su8XWHC0io3t7Uv/CQy38ff4YLn3ue8b0TuC568eREhNObISVpxdnUlZtZ0q/JLYdLsXmdHLLdLOw0GBoKUYIWkOwLQK3AFQEuWTGyqd1sa2r34TP74eN/2lcCLa8p107Y6737AsNY3vv+VxVmUwSZfxu7Pmc070rXPkqvDNfZ2IMv1yn34FeWLX2RXjzMp2rfe3bPhbIpmydNTSql2+GxtDucaz+5WziIq11DVrunzMQh9PJqysO8NV2nat9zrCupJ9AmQiDobNihKA1OFtpEeTv0mllcT2aHncqLIKiLL3gZdglMGyeXjm59iWoKGqYNeP29feaCF0G+Rz681e7sUbEUmiP4vu9hZwzrKtu+3fN27DsTzoX3U2faVoUCnbClDtxdh+HeNXk2ZJTQlpylF/XTmK07z4R4cHzhvDAuYMpLK8l51gl/RvpG2wwGJrGBItbQ2tdQx/col0xzVFnEQRRCFY+rVNA5z6pt8dcpwVu638bjs3doBe2eFsDwMq9hSzfU8Bds/ozMS2JVVlFnoNh0XDuY5DiVcPHEqoXGSWm4Zz5K879x7f86ctddYc3Zx/3cQsFgojQJTacsX0SiQswxdRgMPhihKA1uF1DjhYKQVWJzpdvbsWoWwCqjnlEp7U4HfD6Rbrcgfe+XQv0qlP3St9uI3SHrE1v+Z6fuwG+fFCXahhxed1upRRPfrWLHvER3DQ1jan9k9mdV0ZBWTOf7fw/w52rWZ1bw978ct5cdZCSylrySqs5WlrN6F4tEwKDwXDiGCFoDa21COzVYK9qvjNRuVdswDtOUJINexa27J77l+vVot//w5PmmbNOi83Qi33HjrkBjm6Bhb/W5R3euwFenoW9cB+bRj/is7ryow25bM45zv3nDCLCamF6f12EbNW+IpokxALWSD7ZmEt4aAhVNgdvrz3EZld8YHTvdryi12BopwRVCERkrojsFpG9IvKwn+N/F5FNrp89IhJAdazTgNYGi+2uCpCuRuWN4u0S8o4TrHxG5++3hI2uN/zifZ6Stzs/04W3Bp7jO3bklTo9dNWzup7MvuVw1i+4KfZlLlvZh+V7tCgVV9Ty2Bc7GN83kSvG6eXwI3rGExsRysq9hdRnT14ZN76yhvwy/fmrbQ6+3HqUi0f3YMaAFN5YeYCMg8ewhAjDexghMBhONUETAhGxAM8B5wPDgGtFZJj3GKXU/UqpMUqpMcAzQACrmk4DWiMESulSsuDpVNQY5fk6pRPqWQSHdEVHZ4CVMatKdI2f0dfphtkb39Lz2PWFrnZYv35KVBI8sBseOa5/fplNwYSfsyq3FgHuf28TR45X8ccvdlJWbefxy0YS4srisYQIU/olszKroUXwwfocvsss5NHPdgCweGc+ZTV2Lh3Tkx+ekU5eaQ1vrjrIkG6xgbV2NBgMJ5VgWgSTgL1KqX1KqVrgXeCSJsZfC7wTxPmcPFrjGnLYAKVL0R7ZrFfhNkZFgS5nC74WwfFs/dveRG15b7Z9qMdOuk0Xztr+sS6idWy/zukPgKW78lEK/j5/DNU2B9e/vIYPN+Rw+1n9GNzNt0DY9P7JHCquJLu40mf/kl35hIWG8PmWIyzdnc/HG3NJjQ1nav9kzhrYhQGpMVTZHIwy8QGDoU0IphD0BLK9tnNc+xogIn2BdGBJI8d/LCIZIpJxWrSjbI1FYHdZAwPOBpTOsW+M8nzdVBv0Qi83biFwWxb1UcpXODa9BanD9KreMTfosr+f3g2Irv0TAIt25tE9PoJ5o3vwp8tHsq+wgr7JUX47ek0f4IoTeFkF2cWV7M0v5/45g+jfJZpff7SVZbvzuWRMDywhQkiI8MMZehHY6F7GLWQwtAWnyzqCa4APlFIOfweVUi8BL4GuPnoqJ+aX1giBu0NU3+mQtUzHCbyycDzXtkFVsW7kYY32uIaqS3X9cvCISn12fgrv3wSDzte1e3LXw7l/1Kt6+0yBpP46DbT35ICqplbbHHyXWcgV43siIlwypidKwfAecX5dOANSY+gSG87yPQVc7Wrcvmy3FqbzhndlfN9Ern5RxykuHet5J7hiXC8qauxcPLqZ9RUGgyEoBNMiyAV6e233cu3zxzW0F7cQtM415HbnhEXr5hJZyzxZPN5UuIKt0V0gpovnDb/U66trzCLId+XkH1ypg8ohoTBKF3NDRK8VgIDdQqv2FVFlczB7qEc0Lh3bk4Fd/dSMR+f0XzyqB19tP8qBQl1nfsmufNKSo+jXJYZJ6Un8cEY60/onM6x7XN15YaEh/OiMfkSHny7vJQZD5yKYQrAOGCgi6SIShn7Yf1p/kIgMARKB06OLcyDUWQR+DRj/uIUgNEL3LT1+SGfy1MftCopJhehUTwZRiZeXrTEhKD8KUclw7ybdHnD277SYuBl/C4y6RrdTDIDFO/OICrMwtV/g9fnvOKsfoSHCs0v3Um1zsDKriJmDU+uO/99Fw3j7timN9wYwGAynnKC9giml7CJyN7AQsACvKqW2i8ijQIZSyi0K1wDvqvbUIcdtEbRksZf74R0aoRuag6786e7Z6sbtCopO1WJQlKW3jwcgBGVHdfpnVBLM/r+Gx6OT4fIXA5quUorFO/M5Y2BKizJ5UuMiuGFKX15feYARPeKosTuZNSS1+RMNBkObEVRbXCm1AFhQb99v620/Esw5BIVWuYZcK26tEdrtAx6fvzduV1BMFz3Onft/PMfrWk0IgbuX7wmy/XApR45Xc/85g5ofXI/bz+rHW2sO8scFO4mwhjA5Pan5kwwGQ5thVha3hhPJGgqN9DQ4r/XT1NztCopOhZiuOs3UYfcVgqYsgpMkBG+uOkiYJYTZrXibT42N4IbJfbE5FNP7t8yiMBgMpx4jBK2hziJoQYzA5hUjCA3XC8Zq/AhBeQFYo7RYxHQBFFQWatdQVIrrWn6EwOnU8YWTIASHiir5cEMO107qTXJMeKuucftZ/UmNDeeSsX4zhg0Gw2mESdNoDa2yCFxCYHW1TgyLgZryhuMq8j2uo2jX23h5vrYIUgbBoUL/QlBZqPsFxLRcCA6XVBFqkbq2js8uzSQkRLhz1oAWX8tNl9hw1v56TqvPNxgMpw5jEbSGOiFoQbDYO2sIIDy2EYsgXweJwfO77AiUHvaUdPYXIyjTzVlaahEcr7Qx79nvmfPUcpbuzudgUQUfbsjlukl96Bpn+v0aDJ0BYxG0FKdDv3lD6ywCbyGo9WcRFECiq92i2zI4skXfM8UVuPVnEbRSCJ74aifHKmvplxLNra+vo3+XGEJDhDtn9m/+ZIPB0CEwFkFL8U4ZbU2MwBqpf7fEIji8Qf92WwT+hKC85UKwdn8x76zN5tbpaXx69wzmje7B3vxyrpvch1RjDRgMnQZjEbQUt1sIWpk15Aq+hsU07EnssENlkUcAwmJ0llHuer2dmK5XCzdlEcQ0XzoCoMbu4Fcfb6VnQiT3nzOIyDAL/5g/husm9WlxlzCDwdC+MULQUrwtgpYsKHOvIwj1sgiO7fcdU1kEKI9LSERnDpUc0tvxPXVGUWNCEJnkERo/KKVYsbeQb/cUsGx3AXvzy3nt5olEhYW6bidMbsEqYoPB0DEwQtBSWmsR2Kp0ymiIyxsXHtPQNeReQxDjlbsfnaqFIDJJ1ykKjWg8WNyEW6iixs5DH27hiy1HCLOEMCEtkR/OSDerfg0GgxGCFuNsZYzAXu0JFAOExzVMHy33Wkzmxi0KCa76fdbIxmMEXkLw/5ZnsTKriCn9khjeI57Hv9hJZn4ZD80dzC3T0okMM4u8DAaDxghBS/EJFrcwa8hbCMJidH8Ap0P38QVPzMDHInC5ieKbEYKyo5AyGNDF4p74chcpMeF862ovmRBl5Y1bJ3HGwC4NzzUYDJ0aIwQtpdWuoWrPYjLQMQLQKaTulpHuyqPRXg9rd/A3XvcG9isEXquKc45V8rP3NzOsexwf3TmN0mobGw6WMLp3PN3jIwOfr8Fg6DQYIWgpPkLQkmBxVT3XkKveUE2ZlxDk6zHhXvX+3daBWwhCIxu2qqwsAqcde3RX7n57Iw6n4vnrxxFhtRBhtTB3xMmpP2QwGDomZh1BS2ntOgJ7TT0hcD3sveMEFQU6PuBdq9+va8i3J7B7DcGagjA2ZZfwxBUjSUuJDnxuBoOhU2OEoKWcSNaQ1cs1E+blGnJTUQjRKb7n9RgDSf2g5zi9bY30LE5z41pDsLkknPhIKxeO7B74vAwGQ6fHuIZaSqsXlFX75vjXuYZKPfsqi3zjAwCJaXDPRs+2P4vAJQRrC8MZ1SvedP8yGAwtwlgELeWEsoa8LAJ/rqGqYt1drClCIxrGCOqEIJRRveIDn5PBYDBghKDleFsEjhPIGgrzCha7qTymew43hTXKb4zAHp5ApdPKyJ6mPITBYGgZRghailsILOEtrzVUf0EZeGIE9lrdsSyyGYvAGuE3RlBm1QJiLAKDwdBSjBC0FLdryBrZ8p7FftNHXTGCqmL9Oyqx6etYo8BRw3OLd/HFliN6X9lR8lUiKTFhdI83VUMNBkPLMMHillInBFEtX1DmLQR17SpdFkFlkf7djGtIhUYgwLPfbCc6Jp5zh3fFWnaUQ7UDGdnTBIoNBkPLMRZBS3G7hqyRLa81ZK33th7mVXiu0mURNOMaWrpPC8e0PlEUlteweMcRVHkeWVUxjOpl4gMGg6HlBFUIRGSuiOwWkb0i8nAjY64WkR0isl1E3g7mfFrF5z+D9a97tt0WQVhU4CuLnU5w1PhmDYFvl7I611DjQvB+RjZf7S4B4P9dM4zu8RF8vno74rSRpxJMfMBgMLSKoAmBiFiA54DzgWHAtSIyrN6YgcAvgelKqeHAfcGaT6vZ8xXs/9azXWcRtMA1VNemsl6vgPDYgF1D1TYHf1m4mx4pWiisjhqumtCbnfsPAFCk4hjZ0wiBwWBoOcG0CCYBe5VS+5RStcC7wCX1xtwGPKeUOgaglMoP4nxah6PWt8ibj2uohUJgbWgRVJWX8PiCnTgrfF1Df/tmD6uyiuqGvrXmEAVlNZw/1tXP2F7F/Im9iacCAEtUomkvaTAYWkUwhaAnkO21nePa580gYJCIfC8iq0Vkrr8LiciPRSRDRDIKCgr8DQkeDYTA5Q4KbUGMoH7jejdhMRQfK+alb/dxrPAIWKPBGsGxilqeXpzJbf/OYPfRMqpqHbywLIup/ZIZ3MtVhM5WRc+ESKb3sgKQmhpYi0qDwWCoT0BCICIficiFInKyhSMUGAjMBK4FXhaRBhFPpdRLSqkJSqkJXbqc4nr6DpvvSl5HLUgIhIYF3qrSLST1hSA8Fme1Th+tKCmoiw/sOqoDyDV2Bz98Yx3PLMmksLyG+88Z5LEqXNc8J127m3p3N/WFDAZD6wj0wf48cB2QKSJPiMjgAM7JBXp7bfdy7fMmB/hUKWVTSu0H9qCF4fTBUeu7ktdR62o5aW3oGqop928luPsV18saqpRIwhzatVNbVgiReg3BrqNaHJ6/fjwFZTU8vyyL6QOSmZSe1EAIhic6ATh3fCD/SQwGg6EhAQmBUmqRUup6YBxwAFgkIitF5BYRsTZy2jpgoIiki0gYcA3wab0xn6CtAUQkBe0q2tfiTxEsnE79sPdeyeuwuYQg1FcIlIKnx0LGqw2v4+4xXC9rKKcylBiqiAkP1cFiV6B415EykqLDmDM0lb/PH0NSdBg/P3ew7zVc17TUatEwriGDwdBaAl5QJiLJwA3AjcBG4C1gBvADXA9zb5RSdhG5G1gIWIBXlVLbReRRIEMp9anr2LkisgNwAA8qpYrqX6vNcKeH2usFiy1WlxB4vf07bLr5fNHehtex+c8a2lcqDJIazh3ShfBdJRA1HNAWwZBusYgIF4zsztzh3QgJcS0Uq2cRUFWixaF+RpLBYDAESEBCICIfA4OBN4GLlVKu2ga8JyIZjZ2nlFoALKi377defyvgZ66f0w93hpCtXozAEqb7DHtbBO6xVccaXsdP1pBSil3FirnAqNRQ4naWUm1NwOpU7M4r47pJfevG1omA9zXcQlBdApFmIZnBYGg9gVoETyullvo7oJSacBLnc3rhDgZ7Zw057V4WgVewOBAh8AoW784r42iNFawwLNFJvFSS7YjGVlRBtc3JkO6xDa8DfoTgOEQYITAYDK0n0GDxMO9sHhFJFJE7gzSn0wf3w72BayhMi4GPReASBX9C4CdraEVmIRVKbw+K0KuFc6oj6zKGhnaL8z+nuhiBS1yqSjw9jw0Gg6EVBCoEtymlStwbrgVgtwVnSqcRbiFw2j0P+jrXUP0Ygcci2H74OGMe/ZoDhTojyF/W0HeZhcTE6yyhhJrDAOyvDGfX0TJCBAZ2jfE/J0uozlhyZzIZ15DBYDhBAhUCi3iVtXSVjwgLzpROI7zXCbjf6h02l2uo8RjB0l35lFTaWLrbtVDa7msR1NgdrN1fzIBe3fT+YwcB2FVqZdeRUtJToomwWhqfl3ffYuMaMhgMJ0igQvAVOjA8W0RmA++49nVsvLuRuV0xPhaBP9dQCRsPavfQ2v2ushE23xjBqqwiqmwORvbrpfeXaCHYWhzK9sOlDOneiFvIjXff4qrjxjVkMBhOiECF4BfAUuAnrp/FwEPBmtRpg7cQ+FgEXgvKlPIdqxzsydZJVWv3F6OUapA19OXWo8SGhzJ6gGu9ncsiyLdHkVtSxdBujQSK3bj7FjsdUHPcuIYMBsMJEVDWkFLKCbzg+uk8+HUN1eoHcYjrq3M6tN/ea6yqOsaY3gPZlF1CVkE5A+zVgIAlDJvDycIdR5k9NJXwKNcD3GURHEMLwJDGAsVu3H2L3d3NjGvIYDCcAIHWGhooIh+4+gbsc/8Ee3JtjjvICx4/v/c6AvC4h7ysh3jKueOs/gCs2V+s395DI0CENfuKKam0cf7I7p52laWHUZZwqkUvCms0ddSNu29xlSt+bywCg8FwAgTqGnoNbQ3YgVnAv4H/BGtSpw0+riF3jMCrxAT4FYLuYVWcM6wrqbHhrNlXrM91ZQwt2HaEqDALZw3q4mlXiUKikujXJZbY8FB6JtQrV10fa5S2UKpdQmBiBAaD4QQIVAgilVKLAVFKHVRKPQJcGLxpnSb4uIZcwVnvEhPgWVTmNXZ0ssISIkzul6zjBLYqCI3A4VQs3HaUs4ekerKCwlxWQWQSF43qzrwxPZrvOxwaoS2U6uN627iGDAbDCRDoyuIaVwnqTFf9oFygkUT305/9hRU4laJ/l2Y+Qr2sIaUU4r2gDDxrCbzGDknQVsKk9CQ+23yYysoKokMjWLu/mKKKWi4Y6VUyOjxWt6mMSuK+OYMC+wDWSCg7YlxDBoPhpBCoRXAvEAXcA4xHF5/7QbAmFWwe+mAzt76+Tmf0NIXXwz2vuIQZTy6lqqam2RhB/2htHUxO1/0FjpWWgjWSBVuPEGENYeZgr54K4a54QBO9ihtgjTSuIYPBcNJo1iJwLR6br5R6ACgHbgn6rIKIUopdR8ooq7Gzdn8xk/v57xEM+Lh7Fm7cT25JApURVVgllNAGMQLP2B4ROp4woEsMiVFWiktKcSgHbx46yLzRPYgK8/ra3a6hRnoV+8UtBG6LwLiGDAbDCdCsRaCUcqDLTXcIjhyvpqxGP7w/WJ/jd4zd4aTG7vB5y888XMCcoalYlI2tR6uaDBZH2HRaZ0iIMCk9iYqKCgqqhXtmD+Txy0f63sxtEUS2wCIIjfTECEJCISw68HMNBoOhHoG6hjaKyKcicqOIXO7+CerMgsSePF3UrX+XaL7YeoSKmoYN6P+xKJMJf1jEzhxPa4TkcCf/vGYskSEONuaWU1ytO4Nl7Mvn79/s4f21WQCUW+J9Cs/dNWsAaQkhjErvxs/OGaSb0HjjTiFtrWsoIh6aCy4bDAZDEwQqBBFAEXA2cLHr56JgTSqYZOaVA/CLuUOorHWwYOuRBmO+21tIWY2d99Zk1e2bmR5NdHgoYeKgllBeXpENwMMfbOTpJZlkF+gMHktsVx8hGNUrge5REBYe5X9CdTGCFrqGHLVQWWzcQgaD4YQJdGVxu44LeLMnr4yUmDDOGdaVtOQoPlifw1UTPK2Va+1Odh4p5QdT+zIuNxpcdeNGdg0HpRCnjbFpqby6txrC4DfnD2LK1DOJWLcfvobIxG5QXuB7U/eCMn+EtcI15O5JUHbUZAwZDIYTJtAOZa8BDVJslFK3nvQZBZk9+eUMTNVtIK8c34u/fr2HQ0WV9EnWb+x78sqotTuZmJ7EhYkpsAScoRFYHDV1AeFJA7oxbPwg+BhmDkgEq8UTI4jpCgV7fG9qa0IIWmMRuHsSlB2B5P6Bn2cwGAx+CNQ19DnwhetnMRCHziBqVyil2JtXxiBXrf/Lx/VCBD7ZlFs3ZkuOdvGM6pmAuB78IeFxekGZ62EvFiuxka4He906AlfWUEzXhs1p7FU+vQh8qIsRJAb+QbwtAuMaMhgMJ0igrqEPvbdF5B1gRVBmFEQOH6+motbBwK76LbxHQiSjeiWwZFc+98weCMDW3BISoqz0Tor01BWyRmr3jvut3xKmC82B18riWpAQ/WbvqNHBXPcD217jeYuvT99pMGAOxPUK/IO4r+uoMa4hg8FwwgRqEdRnIJB6MidyKnBnDA3q6inqNmtwFzbnlFBUrgvMbck5zsie8brMg7cQ2Ko8b/0+JSa80kctYRDperP3tgpsVbqukD96jocbPoTQFvT5sXqJirEIDAbDCRJo9dEyESl1/wCfoXsUtCsy64TAU1ri7CGpKAXfZhZQbXOw+2gZo3q5Vuq6u5H5swjqC4HT7l8IHHZQDt+H94niHW8wq4oNBsMJEpAQKKVilVJxXj+D6ruL/CEic0Vkt4jsFZGH/Ry/WUQKRGST6+dHrfkQgbInr5wuseEkRHnevkf0iCclJoyluwrYdbQMu1MxsqfrLdv9lh/qtgiaEAJ3Mbr6QmBv2Lj+hLF6paIa15DBYDhBArUILhOReK/tBBG5tJlzLMBzwPnAMOBaERnmZ+h7Sqkxrp9/tWDuLSYzr4yBqb6F5kJChLMGpbJ8TwEbD+mHt8cicLuGIrQQuB/67p7F4Ft0zp9FUK9N5UnBO/BsXEMGg+EECTRG8Dul1HH3hlKqBPhdM+dMAvYqpfYppWqBd4FLWjfNE8fpVGTml/vEB9ycPSSV41U23lx9kJSYMLrHux607rd8a5Qf15Cr+qjDqwy1X4vA3aYySBaBcQ0ZDIYTJFAh8DeuuYyjnkC213aOa199rhCRLa4OaL39HD8p5JZUUVnrYGDXhqWnZwxMwRIi7CuoYFSvBE8/gDrXUIRP+mjjriE/FoFbCBrLGmoN3taFcQ0ZDIYTJFAhyBCRv4lIf9fP34D1J+H+nwFpSqlRwDfAG/4GiciPRSRDRDIKCgr8DWmWzPyGGUNu4iOtjO+rH+Aje3q9YdcFi12tIQPJGgqL1tZCnWvIHSNoJGuoNfhYBEYIDAbDiRGoEPwUqAXeQ7t4qoG7mjknF/B+w+/l2leHUqpIKeVuDPwvdK+DBiilXlJKTVBKTejSpYu/Ic3irjE0KNV/P+Czh+hs2Lr4APgGi+31g8X1YwQu0RDRVkGdReD6eCcza8hqsoYMBsPJI9AFZRVAg6yfZlgHDBSRdLQAXANc5z1ARLorpdxV3+YBO1t4j4A5f0R3uidEEh9l9Xv8yvG9OHq8mmn9Uzw7G6wj8OcasvmOhXpCEISsIW83kxECg8FwggRaa+gb4CpXkBgRSQTeVUqd19g5Sim7q63lQsACvKqU2i4ijwIZSqlPgXtEZB5gB4qBm0/o0zRBn+SounpC/kiJCeeRecN9d9ZfR2B3CUFIqFerSq/GNHVCkBDcrCFLqHY/WaM8lonBYDC0kkB7Fqe4RQBAKXVMRJpdWayUWgAsqLfvt15//xL4ZYBzOPU4arXP3/0Qr9FxhkaDxW73T2QilLq8YMHIGgItAsYaMBgMJ4FAYwROEenj3hCRNPxUI+1w1LmGXJZEtSuD1kcI6q0jAJdryKWbwcgaAi0skUYIDAbDiROoRfBrYIWILAcEOAP4cdBmdbrgnTUEUOMWAu8FZf5cQ4nBzRoCbX2YjCGDwXASCDRY/JWITEA//DcCnwBVwZzYaYF31hBAte5F7H9BWa0nbhCZCLXlOqYQjKwhoS2UyAAAEFlJREFUgNjukND35F7TYDB0SgINFv8IuBedAroJmAKsQreu7Li43/LdD/EabyFoZB0BeBaVVZd4ZQ2dZIvgmrc9wmMwGAwnQKAxgnuBicBBpdQsYCxQ0vQpHYC6EhP1LQKrnxiBzdciAKgo9MoaOskWQVSSp7uZwWAwnACBxgiqlVLVIoKIhCuldonI4KDO7HTAu8QE1LMIQgDxbxGkDNK/37wU4nu50k0D/aoNBoPh1BKoRZAjIgno2MA3IvI/4GDwpnWaUOca8pM1BPoB708Iuo+CWxdCUn/IXe9bEsJgMBhOMwINFl/m+vMREVkKxANfBW1WpwveZajB5RoST8aQxeq1stjm67PvMwVuWQBZiz2ZQwaDwXAa0mJ/hVJqeTAmctqhlH/XkCVM1xMCl0XgZx2BGxHdj9hgMBhOY1rbs7jj411p1Ns15P3WH2LRriGn09Oq0mAwGNoZRggaw7vAnNs1ZKusJwSuGIHTSzQMBoOhnWGEoDG8hcA79dP7rT8kVFsO3mMNBoOhnWGEoDG8XUOh4ejKGtQTAquOEdSNNUJgMBjaH0YIGsP7LV/Es6jMX4ygbqxxDRkMhvaHEYLGqO/ucWcO1XcN+QiBsQgMBkP7wwhBYzjqBYD9WgRuITCuIYPB0H4xQtAY9d/y64TA62FvqW8RGNeQwWBofxghaIz6b/mhfoTAuIYMBkMHwAhBY9R/y3evJTCuIYPB0MEwQtAYgbiGGlgExjVkMBjaH0YIGiNg15DDuIYMBkO7xghBYzTmGgrxqtNXt7LYuIYMBkP7xQhBYzRwDUX5bkND11CIaT5jMBjaH0EVAhGZKyK7RWSviDzcxLgrRESJyIRgzqdFNHANmQVlBoOhYxI0IRARC/AccD4wDLhWRIb5GReL7om8JlhzaRUNXEONlZgwtYYMBkP7JpgWwSRgr1Jqn1KqFngXuMTPuD8ATwLVQZxLy3HU6N8ma8hgMHRwgikEPYFsr+0c1746RGQc0Fsp9UVTFxKRH4tIhohkFBQUnPyZ+iOQrCF3q0rjGjIYDO2YNgsWi0gI8Dfg582NVUq9pJSaoJSa0KVLl+BPDjwP91C3RWAWlBkMho5JMIUgF+jttd3Ltc9NLDACWCYiB4ApwKenTcA4oOqjlnrrCIxryGAwtD+CKQTrgIEiki4iYcA1wKfug0qp40qpFKVUmlIqDVgNzFNKZQRxToHjfssPcQeLA0gfNRaBwWBohwRNCJRSduBuYCGwE3hfKbVdRB4VkXnBuu9Jw1GrH/Qhrq+oMdeQwwYOe8NjBoPB0E4I6goopdQCYEG9fb9tZOzMYM6lxThqfd/w/ZaYsHpcQ2LRriKDwWBoZ5iVxY3hsPm+4TfXqtK4hQwGQzvFCEFj1H+4N9ehzAiBwWBopxghaIwGrqFmSkyY+IDBYGinGCFojPquoegUkBCISvHss1hBOfQqZGMRGAyGdoopl9kY9S2C+F5wdwYkpnv2uYPDtipjERgMhnaLEYLG8Of3T+7vu+0uO22rMhaBwWBotxjXUGME4vevE4JKIwQGg6HdYoSgMQJJCfWxCIxryGAwtE+MEDRGICmhbiGoNRaBwWBovxghaAzjGjIYDJ0EIwSNYQ8gJdS4hgwGQwfACEFj1F9H4A9jERgMhg5A5xQCW5X26zdFi4LFlcYiMBgM7ZbOKQQf3w4f3Nr0mECCxRaXEJiicwaDoR3TOReUFWVB2dGmx7QkWAxGCAwGQ7ulc1oEFYVQWQiVxY2PcdSCJbzp6/gIgXENGQyG9knnEwKloLJI/124p/FxLVlHAMYiMBgM7ZbOJwQ1ZeB09SNuUgiMa8hgMHQOOp8QuK0BaFwIlGpZ1hAY15DBYGi3dEIh8IoLFDQiBE4HoIxryGAwdAo6oRC4LIL4Po1bBI5a/du4hgwGQyegEwpBof7ddyqUHARbdcMxdULQnEVg8fxtXEMGg6GdElQhEJG5IrJbRPaKyMN+jt8hIltFZJPI/2/v3mPkKss4jn9/u9uWXtS27IrS7ZYCpVgFCmyggBcCjeFigD8wgoDEkDQaiCAmAgE19j/BgJc0CAG0KHIVtCEoSCUokRYKFAQKtCD0kmK3Fy6lSG+Pf5wzzOzujDvs7tnpmfP7JJOZ887b6fv23c6z73POeV89JmlWlu0ByjOCrmMgdsPmV/vX2ZWeTB7oy73yfc8IzCynMgsEklqBBcDJwCzg7Cpf9L+PiEMiYjZwNXBtVu350LZN0DIKphyZHFdLD9U9I3BqyMzyL8sZwVHAqoh4LSK2A3cAp1dWiIh3Kg7HA5FhexLbNsG4vWHvAwFVP2E8qEDg1JCZ5VOWS0xMAdZUHK8Fju5bSdKFwKXAaOCEah8kaR4wD6Crq2tordq2OQkEo8fBxKk1ZgR1poZ6nSPwjMDM8qnhJ4sjYkFEHABcBlxVo86NEdEdEd0dHR1D+wu3bYJxk5PX7QfBxpf719n1QfLs1JCZFUCWgWAdMLXiuDMtq+UO4IwM25N4b2MyIwBonwkbV8Hu3b3r1J0aqjxZ7NSQmeVTloHgSWCGpOmSRgNnAYsqK0iaUXF4KrAyw/Yktm2C8e3J6/YZsPN9eGdt7zp1p4Z8jsDM8i+zcwQRsVPSRcCDQCtwS0S8IGk+sCwiFgEXSZoL7AC2AOdn1R4guWP4/S3lGUHHzOS55xWYWHHuYVD3ETg1ZGb5lOl+BBHxAPBAn7IfVry+OMu/v5/33wKiIjV0UPLc8xLMmFuu56uGzKxAGn6yeESVbiYrBYLx7fDxTli3rHc931BmZgVS0EAwuVw27Rh44/FkxdES31BmZgVS0EDQXi7rmgNb34Qtr5fLPpwRDPDlLq81ZGb5V7BAkC44V0oNAXQdmzyvfrxcVvfqoy2g9J/QMwIzy6mCBYIqqaGOg2GvifDGP8tlpUDQNsCexVBODzkQmFlOFSwQbIZR42HU2HJZS0uSHlq9pFxWb2oIyjeVOTVkZjlVsECwqXdaqKRrDmxaCVt7kuN6U0PgGYGZ5V4BA8Hk/uWl8wRr0llBvVcNQfmmMgcCM8up4gWC8e39y/edDa1jkstI4SOmhkozAqeGzCyfihUIKhecq9Q2Bjq7y1cO7dqeXA1UuYRELU4NmVnOFSsQlPYiqKZrDqx/NgkWu7bX/8XemgaCFs8IzCyfihMIdn4A29+tfo4AYOYpyR7GvzwSXnmo/kDQ0pY+ivNPaWbNpTjfXts2J8+1ZgSd3fCtf8DUo6FnRe9LTP+fljanhcws1zJdfXSPUm15ib4+dQiccxesXlrepWwgLW0+UWxmuVbAQFBjRlCpq9/WyrV5RmBmOVeg1FCVdYaGgwOBmeVcgQLBAOcIBsupITPLueIEgtETYJ9DYOyk4f1czwjMLOeKc45g9tnJY7i1tDoQmFmuFWdGkJXWUU4NmVmuFWdGkJWjvw07tjW6FWZmg+ZAMFQHfbnRLTAzG5JMU0OSTpL0sqRVki6v8v6lkl6U9JykxZKmZdkeMzPrL7NAIKkVWACcDMwCzpY0q0+1Z4DuiDgUuAe4Oqv2mJlZdVnOCI4CVkXEaxGxHbgDOL2yQkQ8EhGlBPsSoDPD9piZWRVZBoIpwJqK47VpWS0XAH+u9oakeZKWSVrW09MzjE00M7M94vJRSecC3cA11d6PiBsjojsiujs6Oka2cWZmTS7Lq4bWAVMrjjvTsl4kzQWuBL4UEXUu+WlmZsMlyxnBk8AMSdMljQbOAhZVVpB0OHADcFpEbMiwLWZmVkNmgSAidgIXAQ8CK4C7IuIFSfMlnZZWuwaYANwtabmkRTU+zszMMqKIaHQbPhJJPcAbg/zj7cDGYWzOnqRZ++Z+5U+z9i3v/ZoWEVVPsuYuEAyFpGUR0d3odmShWfvmfuVPs/atWfsFe8hVQ2Zm1jgOBGZmBVe0QHBjoxuQoWbtm/uVP83at2btV7HOEZiZWX9FmxGYmVkfDgRmZgVXmEAw0N4IeSFpqqRH0n0cXpB0cVo+WdJfJa1Mnyc1uq2DIalV0jOS7k+Pp0tamo7bneld6rkjaaKkeyS9JGmFpGOaYcwkfTf9OXxe0u2S9srrmEm6RdIGSc9XlFUdIyV+kfbxOUlHNK7lQ1eIQFDn3gh5sRP4XkTMAuYAF6Z9uRxYHBEzgMXpcR5dTHIneslPgOsi4kBgC8kqtXn0c+AvEXEwcBhJH3M9ZpKmAN8h2VPkc0AryVIyeR2z3wAn9SmrNUYnAzPSxzzg+hFqYyYKEQioY2+EvIiI9RHxdPr6XZIvlCkk/VmYVlsInNGYFg6epE7gVOCm9FjACSSbFkF++/UJ4IvAzQARsT0i3qIJxoxk4cqxktqAccB6cjpmEfF3YHOf4lpjdDpwaySWABMlfXpkWjr8ihIIPureCLkgaT/gcGApsE9ErE/fehPYp0HNGoqfAd8HdqfHewNvpetWQX7HbTrQA/w6TXvdJGk8OR+ziFgH/BRYTRIA3gaeojnGrKTWGDXVd0pRAkHTkTQB+ANwSUS8U/leJNcE5+q6YElfATZExFONbksG2oAjgOsj4nDgPfqkgXI6ZpNIfjOeDuwLjKd/aqVp5HGM6lWUQFDX3gh5IWkUSRC4LSLuTYv/U5qaps95W9b7OOA0Sa+TpO5OIMmrT0zTDpDfcVsLrI2IpenxPSSBIe9jNhf4d0T0RMQO4F6ScWyGMSupNUZN9Z1SlEAw4N4IeZHmzW8GVkTEtRVvLQLOT1+fD/xppNs2FBFxRUR0RsR+JOPzt4g4B3gEODOtlrt+AUTEm8AaSTPTohOBF8n5mJGkhOZIGpf+XJb6lfsxq1BrjBYB30ivHpoDvF2RQsqfiCjEAzgFeAV4Fbiy0e0ZQj8+TzI9fQ5Ynj5OIcmnLwZWAg8Dkxvd1iH08Xjg/vT1/sATwCrgbmBMo9s3yD7NBpal4/ZHYFIzjBnwY+Al4Hngt8CYvI4ZcDvJuY4dJLO4C2qNESCSKxFfBf5FcuVUw/sw2IeXmDAzK7iipIbMzKwGBwIzs4JzIDAzKzgHAjOzgnMgMDMrOAcCsxEk6fjSyqpmewoHAjOzgnMgMKtC0rmSnpC0XNIN6T4JWyVdl66/v1hSR1p3tqQl6br091WsWX+gpIclPSvpaUkHpB8/oWJvgtvSu3LNGsaBwKwPSZ8BvgYcFxGzgV3AOSSLqi2LiM8CjwI/Sv/IrcBlEXEoyV2mpfLbgAURcRhwLMldq5CsGHsJyd4Y+5Osz2PWMG0DVzErnBOBI4En01/Wx5IsNrYbuDOt8zvg3nSvgYkR8WhavhC4W9LHgCkRcR9ARPwXIP28JyJibXq8HNgPeCz7bplV50Bg1p+AhRFxRa9C6Qd96g12fZYPKl7vwv8PrcGcGjLrbzFwpqRPwof71k4j+f9SWlXz68BjEfE2sEXSF9Ly84BHI9k9bq2kM9LPGCNp3Ij2wqxO/k3ErI+IeFHSVcBDklpIVqO8kGRDmaPS9zaQnEeAZHniX6Vf9K8B30zLzwNukDQ//YyvjmA3zOrm1UfN6iRpa0RMaHQ7zIabU0NmZgXnGYGZWcF5RmBmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZw/wOSluR1nk5TNgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content.gdrive/MyDrive')"
      ],
      "metadata": {
        "id": "XB1pmjcGGsgw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict new Dataset to learn\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Datasets_1575/data_Manually_Labeled_09042022.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X2 = np.array(data2[\"keypoints\"])\n",
        "y2 = np.array(data2[\"labels\"])\n",
        "print(y2)\n",
        "print(X2[0:1].shape)\n",
        "print(X2[0:1])\n",
        "\n",
        "predictions = model.predict(X2, batch_size = 10, verbose =0)\n",
        "print(predictions)\n",
        "counter = 0\n",
        "for i, x in enumerate(predictions):\n",
        "    if np.around(x) != y2[i]:\n",
        "        print(\"wrong\")\n",
        "        counter += 1\n",
        "\n",
        "print(\"error:\" , counter / y2.shape[0])\n",
        "print(type(predictions))\n",
        "y3 = np.around(predictions)\n",
        "y3 = np.reshape(y3, (X2.shape[0]))\n",
        "print(y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgoXxEiVlqbn",
        "outputId": "503f9f80-fab8-43e6-dbc3-35c7c42555b0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(1, 1575)\n",
            "[[0.         0.         0.         ... 0.41105416 0.75302452 0.73161852]]\n",
            "[[0.29595634]\n",
            " [0.1733788 ]\n",
            " [0.2066136 ]\n",
            " [0.12075743]\n",
            " [0.27811733]\n",
            " [0.24224457]\n",
            " [0.31926638]\n",
            " [0.30953616]\n",
            " [0.49361354]\n",
            " [0.30546921]\n",
            " [0.31209114]\n",
            " [0.3026772 ]\n",
            " [0.11944246]\n",
            " [0.23022702]\n",
            " [0.23193654]\n",
            " [0.24261305]\n",
            " [0.19923738]\n",
            " [0.13036716]\n",
            " [0.39132488]\n",
            " [0.38293043]\n",
            " [0.19547188]\n",
            " [0.17494902]\n",
            " [0.34403962]\n",
            " [0.3559302 ]\n",
            " [0.1470536 ]\n",
            " [0.11557981]\n",
            " [0.2855407 ]\n",
            " [0.18741769]\n",
            " [0.180771  ]\n",
            " [0.22619098]\n",
            " [0.16937858]\n",
            " [0.2780578 ]\n",
            " [0.28306472]\n",
            " [0.23862365]\n",
            " [0.34377566]\n",
            " [0.23134038]\n",
            " [0.22231293]\n",
            " [0.2131688 ]\n",
            " [0.22292617]\n",
            " [0.2655933 ]\n",
            " [0.2751493 ]\n",
            " [0.25121182]\n",
            " [0.2384485 ]\n",
            " [0.29511756]\n",
            " [0.23138228]\n",
            " [0.27256286]\n",
            " [0.16399708]\n",
            " [0.19183472]\n",
            " [0.24553418]\n",
            " [0.15962401]\n",
            " [0.21750408]\n",
            " [0.1890375 ]\n",
            " [0.30441952]\n",
            " [0.22655421]\n",
            " [0.1581901 ]\n",
            " [0.2591524 ]\n",
            " [0.16991153]\n",
            " [0.2741648 ]\n",
            " [0.24027324]\n",
            " [0.28454247]\n",
            " [0.22791573]\n",
            " [0.19908163]\n",
            " [0.19349122]\n",
            " [0.45124272]\n",
            " [0.25895715]\n",
            " [0.18732029]\n",
            " [0.15564221]\n",
            " [0.17861882]\n",
            " [0.13969803]\n",
            " [0.33148682]\n",
            " [0.17564455]\n",
            " [0.3632845 ]\n",
            " [0.32027674]\n",
            " [0.3083427 ]\n",
            " [0.33983624]\n",
            " [0.2938431 ]\n",
            " [0.38117933]\n",
            " [0.49763155]\n",
            " [0.3296861 ]\n",
            " [0.36071485]\n",
            " [0.22595313]\n",
            " [0.27616364]\n",
            " [0.2927454 ]\n",
            " [0.2488612 ]\n",
            " [0.30948007]\n",
            " [0.22041395]\n",
            " [0.39470756]\n",
            " [0.2436111 ]\n",
            " [0.2603709 ]\n",
            " [0.05544683]\n",
            " [0.34025392]\n",
            " [0.41661444]\n",
            " [0.30474406]\n",
            " [0.15808076]\n",
            " [0.17973548]\n",
            " [0.32424417]\n",
            " [0.22801536]\n",
            " [0.2364046 ]\n",
            " [0.17744052]\n",
            " [0.10514107]\n",
            " [0.10423794]\n",
            " [0.24596378]\n",
            " [0.39773333]\n",
            " [0.31230476]\n",
            " [0.31725752]\n",
            " [0.22654292]\n",
            " [0.20386764]\n",
            " [0.13949278]\n",
            " [0.30385667]\n",
            " [0.290707  ]\n",
            " [0.45316294]\n",
            " [0.30501685]\n",
            " [0.35752106]\n",
            " [0.1897757 ]\n",
            " [0.40180692]\n",
            " [0.22574505]\n",
            " [0.2734425 ]\n",
            " [0.32001114]\n",
            " [0.1795533 ]\n",
            " [0.24382085]\n",
            " [0.34012127]\n",
            " [0.21212608]\n",
            " [0.21767202]\n",
            " [0.08456051]\n",
            " [0.12966114]\n",
            " [0.137229  ]\n",
            " [0.10566717]\n",
            " [0.10746008]\n",
            " [0.08368793]\n",
            " [0.06627575]\n",
            " [0.273388  ]\n",
            " [0.10227484]\n",
            " [0.05470523]\n",
            " [0.08249831]\n",
            " [0.25063822]\n",
            " [0.15821224]\n",
            " [0.11497861]\n",
            " [0.09771004]\n",
            " [0.062215  ]\n",
            " [0.2663771 ]\n",
            " [0.09682137]\n",
            " [0.08839244]\n",
            " [0.22555494]\n",
            " [0.2372193 ]\n",
            " [0.0983395 ]\n",
            " [0.06996056]\n",
            " [0.09445137]\n",
            " [0.13296545]\n",
            " [0.33552667]\n",
            " [0.11366081]\n",
            " [0.10408923]\n",
            " [0.11045307]\n",
            " [0.15305826]\n",
            " [0.11447316]\n",
            " [0.10632753]\n",
            " [0.28957242]\n",
            " [0.38752782]\n",
            " [0.07423937]\n",
            " [0.09042358]\n",
            " [0.08352602]\n",
            " [0.09466061]\n",
            " [0.49763155]\n",
            " [0.13967434]\n",
            " [0.205524  ]\n",
            " [0.05107865]\n",
            " [0.07556045]\n",
            " [0.09573269]\n",
            " [0.16253844]\n",
            " [0.11365682]\n",
            " [0.36444014]\n",
            " [0.21441716]\n",
            " [0.49763155]\n",
            " [0.13339946]\n",
            " [0.16244376]\n",
            " [0.11786348]\n",
            " [0.1349878 ]\n",
            " [0.36449945]\n",
            " [0.1998724 ]\n",
            " [0.24704516]\n",
            " [0.17564312]\n",
            " [0.22206646]\n",
            " [0.21758035]\n",
            " [0.12464595]\n",
            " [0.07814437]\n",
            " [0.11682612]\n",
            " [0.10118109]\n",
            " [0.2267474 ]\n",
            " [0.10096893]\n",
            " [0.22798955]\n",
            " [0.14216629]\n",
            " [0.14843571]\n",
            " [0.30877367]\n",
            " [0.04198033]\n",
            " [0.05755928]\n",
            " [0.2019651 ]\n",
            " [0.10351536]\n",
            " [0.14132065]\n",
            " [0.05126011]\n",
            " [0.07847252]\n",
            " [0.07076666]\n",
            " [0.10299107]\n",
            " [0.13850543]\n",
            " [0.11460793]\n",
            " [0.19881478]\n",
            " [0.12292466]\n",
            " [0.1094811 ]\n",
            " [0.17018875]\n",
            " [0.11704093]\n",
            " [0.14184189]\n",
            " [0.21733916]\n",
            " [0.09910956]\n",
            " [0.05970946]\n",
            " [0.09581539]\n",
            " [0.18031505]\n",
            " [0.09955645]\n",
            " [0.2630424 ]\n",
            " [0.16789556]\n",
            " [0.16705915]\n",
            " [0.31648648]\n",
            " [0.11511889]\n",
            " [0.11371568]\n",
            " [0.17385122]\n",
            " [0.1080443 ]\n",
            " [0.22687876]\n",
            " [0.2200304 ]\n",
            " [0.09617209]\n",
            " [0.13958946]\n",
            " [0.19123146]\n",
            " [0.06423274]\n",
            " [0.2961595 ]\n",
            " [0.12115601]\n",
            " [0.1327587 ]\n",
            " [0.12267277]\n",
            " [0.24652016]\n",
            " [0.13086   ]\n",
            " [0.14965159]\n",
            " [0.11292621]\n",
            " [0.10180014]\n",
            " [0.09380171]\n",
            " [0.3471039 ]\n",
            " [0.11910605]\n",
            " [0.05472913]\n",
            " [0.07523954]\n",
            " [0.13691384]\n",
            " [0.12965548]\n",
            " [0.09891888]\n",
            " [0.15774262]\n",
            " [0.07688522]\n",
            " [0.27689415]\n",
            " [0.11472559]\n",
            " [0.11678782]\n",
            " [0.2482844 ]\n",
            " [0.06710681]\n",
            " [0.06947443]\n",
            " [0.13664523]\n",
            " [0.1179373 ]\n",
            " [0.14286008]\n",
            " [0.1257571 ]\n",
            " [0.17066738]\n",
            " [0.23045343]\n",
            " [0.12083256]\n",
            " [0.10365796]\n",
            " [0.11061564]\n",
            " [0.12007201]\n",
            " [0.11881086]\n",
            " [0.1076059 ]\n",
            " [0.09594139]\n",
            " [0.1827879 ]\n",
            " [0.10398197]\n",
            " [0.13055837]\n",
            " [0.17757756]\n",
            " [0.17596352]\n",
            " [0.104738  ]\n",
            " [0.1251167 ]\n",
            " [0.1006434 ]\n",
            " [0.2118724 ]\n",
            " [0.3173144 ]]\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "wrong\n",
            "error: 0.4404332129963899\n",
            "<class 'numpy.ndarray'>\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "#merging json files\n",
        "with open('/content.gdrive/MyDrive/Datasets_1680/data_Labeled_01042022.json', \"r\") as fp:\n",
        "    data1 = json.load(fp)\n",
        "\n",
        "# convert lists to numpy arrays\n",
        "X = np.array(data1[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data1[\"labels\"])\n",
        "#print(X[0])\n",
        "#print(X[332])\n",
        "print(X.shape)\n",
        "#print(y[0])\n",
        "#print(y[332])\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "e-dBJlOgnI1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import json files 1680 and reshape\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "#merging json files\n",
        "with open('/content.gdrive/MyDrive/Datasets_1680/data_Labeled_09042022.json', \"r\") as fp:\n",
        "    data1 = json.load(fp)\n",
        "\n",
        "# convert lists to numpy arrays\n",
        "X = np.array(data1[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data1[\"labels\"])\n",
        "X = np.reshape(X, (y.shape[0],1680))\n",
        "\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Datasets_1680/data_Labeled_Max.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X1 = np.array(data2[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y1 = np.array(data2[\"labels\"])\n",
        "X1 = np.reshape(X1, (y1.shape[0],1680))\n",
        "\n",
        "\n",
        "X = np.concatenate((X,X1), axis=0)\n",
        "y = np.concatenate((y,y1), axis=0)\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Datasets_1680/data_Labeled_Mirror_Telemark_01042022.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X1 = np.array(data2[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y1 = np.array(data2[\"labels\"])\n",
        "X1 = np.reshape(X1, (y1.shape[0],1680))\n",
        "\n",
        "\n",
        "X = np.concatenate((X,X1), axis=0)\n",
        "y = np.concatenate((y,y1), axis=0)\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Datasets_1680/data_Labeled_Mirror_Telemark_09042022.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X1 = np.array(data2[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y1 = np.array(data2[\"labels\"])\n",
        "X1 = np.reshape(X1, (y1.shape[0],1680))\n",
        "\n",
        "\n",
        "X = np.concatenate((X,X1), axis=0)\n",
        "y = np.concatenate((y,y1), axis=0)\n",
        "\"\"\"\n",
        "with open('/content.gdrive/MyDrive/Datasets_1575/data_manually_labled_Telemark_mirror.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X1 = np.array(data2[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y1 = np.array(data2[\"labels\"])\n",
        "X1 = np.reshape(X1, (y1.shape[0],1680))\n",
        "\n",
        "\n",
        "X = np.concatenate((X,X1), axis=0)\n",
        "y = np.concatenate((y,y1), axis=0)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(X[0])\n",
        "#print(X[332])\n",
        "print(X.shape)\n",
        "#print(y[0])\n",
        "#print(y[332])\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7cTc4vw4LPL",
        "outputId": "3ded374e-72d9-452a-b99d-8f99d8fcdb2b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(750, 1680)\n",
            "(750,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import json files 1575\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "#merging json files\n",
        "with open('/content.gdrive/MyDrive/Datasets_1575/data_Manually_Labeled_09042022.json', \"r\") as fp:\n",
        "    data1 = json.load(fp)\n",
        "\n",
        "# convert lists to numpy arrays\n",
        "X = np.array(data1[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data1[\"labels\"])\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Datasets_1575/data_Manually_Labeled_11042022.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X1 = np.array(data2[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y1 = np.array(data2[\"labels\"])\n",
        "\n",
        "X = np.concatenate((X,X1), axis=0)\n",
        "y = np.concatenate((y,y1), axis=0)\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Datasets_1575/data_Manually_Labeled_mirror_09042022.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X1 = np.array(data2[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y1 = np.array(data2[\"labels\"])\n",
        "\n",
        "X = np.concatenate((X,X1), axis=0)\n",
        "y = np.concatenate((y,y1), axis=0)\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Datasets_1575/data_manually_labeled_original.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X1 = np.array(data2[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y1 = np.array(data2[\"labels\"])\n",
        "\n",
        "X = np.concatenate((X,X1), axis=0)\n",
        "y = np.concatenate((y,y1), axis=0)\n",
        "\n",
        "with open('/content.gdrive/MyDrive/Datasets_1575/data_manually_labled_Telemark_mirror.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X1 = np.array(data2[\"keypoints\"])\n",
        "#X = np.array(data[\"mfcc\"])\n",
        "y1 = np.array(data2[\"labels\"])\n",
        "\n",
        "X = np.concatenate((X,X1), axis=0)\n",
        "y = np.concatenate((y,y1), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(X[0])\n",
        "print(X[332])\n",
        "print(X.shape)\n",
        "print(y[0])\n",
        "print(y[332])\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2urcYWKzwiCD",
        "outputId": "ba25ce99-91f2-4a93-87be-51e1b263c1ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         ... 0.41105416 0.75302452 0.73161852]\n",
            "[0.         0.         0.         ... 0.54369467 0.74955374 0.53815782]\n",
            "(1082, 1575)\n",
            "1\n",
            "1\n",
            "(1082,)\n"
          ]
        }
      ]
    }
  ]
}