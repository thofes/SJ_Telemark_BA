{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thofes/judging_SJ_BA/blob/main/NN_1575_norm_crop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVN2myC-oH6N",
        "outputId": "327a0ea6-806f-4968-dbb2-71455a43a19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content.gdrive\n"
          ]
        }
      ],
      "source": [
        "#Connect GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content.gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UAMjfuEoISk",
        "outputId": "1b08db28-c955-420e-d00a-a6374c2d5523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data_manually_labeled_original.json', 'data_manually_labled_Telemark_mirror.json', 'data_Manually_Labeled_09042022.json', 'data_Manually_Labeled_mirror_09042022.json', 'data_Manually_Labeled_11042022.json']\n",
            "[1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1.\n",
            " 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0.]\n",
            "(1082, 1575)\n",
            "(1082,)\n",
            "[1. 0. 0. ... 0. 1. 0.]\n",
            "[[0.         0.         0.         ... 0.51103371 0.73097068 0.68072122]\n",
            " [0.48499069 0.36418617 0.49909058 ... 0.         0.         0.        ]\n",
            " [0.64755595 0.31204635 0.14982496 ... 0.49036869 0.67849678 0.5574711 ]\n",
            " ...\n",
            " [0.69263363 0.28733572 0.40521273 ... 0.49002707 0.73333383 0.40215403]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "#import json files 1575\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "PATH = \"/content.gdrive/MyDrive/Datasets_1575\"\n",
        "sets = []\n",
        "try:\n",
        "    sets = next(os.walk(PATH))[2]\n",
        "except StopIteration:\n",
        "    pass\n",
        "\n",
        "print(sets)\n",
        "X = np.empty(shape=(0,1575))\n",
        "y = np.empty(shape=0)\n",
        "\n",
        "\n",
        "\n",
        "for path in sets:\n",
        "    path = PATH + '/' + path\n",
        "    with open(path, \"r\") as fp:\n",
        "        data1 = json.load(fp)\n",
        "\n",
        "    # convert lists to numpy arrays\n",
        "    X1 = np.array(data1[\"keypoints\"])\n",
        "    #X = np.array(data[\"mfcc\"])\n",
        "    y1 = np.array(data1[\"labels\"])\n",
        "\n",
        "    X = np.concatenate((X,X1), axis=0)\n",
        "    y = np.concatenate((y,y1), axis=0)\n",
        "X,y = shuffle(X,y)\n",
        "with np.printoptions(threshold=np.inf):\n",
        "    print(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(y)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for x in y:\n",
        "  if x == 0:\n",
        "      counter+=1\n",
        "\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH6BbA8X3j7X",
        "outputId": "2d2550d0-40e5-4f6e-d8ef-ddeac3b63a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyNWtLCwGbNG",
        "outputId": "d09a5e6d-6f75-4b38-b757-d7f26f82e4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1082, 1575)\n",
            "435474\n",
            "[45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574]\n",
            "(1082, 945)\n",
            "216396\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#with np.printoptions(threshold=np.inf):\n",
        "    #print(X[0])\n",
        "print(X.shape)\n",
        "counter_alt =0\n",
        "for x in X:\n",
        "  for k in x:\n",
        "      if k == 0:\n",
        "          counter_alt+= 1\n",
        "\n",
        "print(counter_alt)\n",
        "\n",
        "delete_index = []\n",
        "for i in range(21):\n",
        "    liste = [*range(45+(i*75),75+(i*75),1)]\n",
        "    delete_index.append(liste)\n",
        "\n",
        "flat_list = [item for sublist in delete_index for item in sublist]\n",
        "\n",
        "print(flat_list)\n",
        "X = np.delete(X, delete_index, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "#with np.printoptions(threshold=np.inf):\n",
        "    #print(X[0])\n",
        "\n",
        "counter_neu =0\n",
        "for x in X:\n",
        "  for k in x:\n",
        "      if k == 0:\n",
        "          counter_neu+= 1\n",
        "print(counter_neu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk8FLAY_qCDE",
        "outputId": "52947aab-2e5a-4a24-d9f2-3e11bef4cb2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi9G7kXLoMoc",
        "outputId": "018bf403-90dd-42e4-c8c5-d71a81259a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 945, 1890)         3780      \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 315, 32)           2721632   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 315, 32)           0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 21, 64)            30784     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 21, 64)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 21)                7224      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 21)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,763,442\n",
            "Trainable params: 2,763,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Creating binary classification model 1575\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Activation, Dense, Conv1D, Dropout, MaxPooling1D, LSTM, Conv2D, Flatten,GlobalMaxPooling1D, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy, binary_crossentropy\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Ranger(sync_period=6,\n",
        "           slow_step_size=0.5,\n",
        "           learning_rate=0.001,\n",
        "           beta_1=0.9,\n",
        "           beta_2=0.999,\n",
        "           epsilon=1e-7,\n",
        "           weight_decay=0.,\n",
        "           amsgrad=False,\n",
        "           sma_threshold=5.0,\n",
        "           total_steps=0,\n",
        "           warmup_proportion=0.1,\n",
        "           min_lr=0.,\n",
        "           name=\"Ranger\"):\n",
        "    inner = tfa.optimizers.RectifiedAdam(learning_rate, beta_1, beta_2, epsilon, weight_decay, amsgrad, sma_threshold, total_steps, warmup_proportion, min_lr, name)\n",
        "    optim = tfa.optimizers.Lookahead(inner, sync_period, slow_step_size, name)\n",
        "    return optim\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    \n",
        "    Dense(units=1890, input_shape=(945,1), activation='relu'), \n",
        "    #Dense(units=945, activation='relu'),\n",
        "    \n",
        "    #Reshape((945,1)),                   \n",
        "    Conv1D(filters=32, kernel_size=45, strides=3, padding='same', activation='relu'), # input_shape=(945,1),\n",
        "    Dropout(0.15),\n",
        "    Conv1D(filters=64, kernel_size=15, strides=15, padding='same', activation='relu'),\n",
        "    Dropout(0.15),\n",
        "    LSTM(21), #, return_sequences=True\n",
        "    Dropout(0.15),\n",
        "    Dense(units=1, activation='sigmoid') #sigmoid\n",
        "])\n",
        "\n",
        "save_callback = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    min_delta=0,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "def scheduler(epoche, lr):\n",
        "      if epoche < 2:\n",
        "          return lr\n",
        "      else:\n",
        "          return lr*0.97\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
        "#model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer=Ranger(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VOEiMkStoTs9",
        "outputId": "82e93e26-6cc5-4b82-cd2c-0a612c5d79a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "22/22 - 22s - loss: 0.6932 - accuracy: 0.5121 - val_loss: 0.7014 - val_accuracy: 0.4562 - 22s/epoch - 986ms/step\n",
            "Epoch 2/1000\n",
            "22/22 - 9s - loss: 0.6909 - accuracy: 0.5434 - val_loss: 0.6997 - val_accuracy: 0.4562 - 9s/epoch - 430ms/step\n",
            "Epoch 3/1000\n",
            "22/22 - 9s - loss: 0.6901 - accuracy: 0.5422 - val_loss: 0.7004 - val_accuracy: 0.4562 - 9s/epoch - 425ms/step\n",
            "Epoch 4/1000\n",
            "22/22 - 9s - loss: 0.6868 - accuracy: 0.5445 - val_loss: 0.7069 - val_accuracy: 0.4562 - 9s/epoch - 424ms/step\n",
            "Epoch 5/1000\n",
            "22/22 - 9s - loss: 0.6847 - accuracy: 0.5491 - val_loss: 0.6944 - val_accuracy: 0.4839 - 9s/epoch - 424ms/step\n",
            "Epoch 6/1000\n",
            "22/22 - 9s - loss: 0.6832 - accuracy: 0.5584 - val_loss: 0.6975 - val_accuracy: 0.4839 - 9s/epoch - 428ms/step\n",
            "Epoch 7/1000\n",
            "22/22 - 9s - loss: 0.6786 - accuracy: 0.5642 - val_loss: 0.7148 - val_accuracy: 0.4562 - 9s/epoch - 424ms/step\n",
            "Epoch 8/1000\n",
            "22/22 - 9s - loss: 0.6730 - accuracy: 0.5988 - val_loss: 0.7000 - val_accuracy: 0.4977 - 9s/epoch - 424ms/step\n",
            "Epoch 9/1000\n",
            "22/22 - 9s - loss: 0.6683 - accuracy: 0.5896 - val_loss: 0.6847 - val_accuracy: 0.5668 - 9s/epoch - 424ms/step\n",
            "Epoch 10/1000\n",
            "22/22 - 9s - loss: 0.6632 - accuracy: 0.5954 - val_loss: 0.7334 - val_accuracy: 0.4793 - 9s/epoch - 428ms/step\n",
            "Epoch 11/1000\n",
            "22/22 - 9s - loss: 0.6647 - accuracy: 0.5884 - val_loss: 0.6714 - val_accuracy: 0.5668 - 9s/epoch - 419ms/step\n",
            "Epoch 12/1000\n",
            "22/22 - 9s - loss: 0.6514 - accuracy: 0.6150 - val_loss: 0.6787 - val_accuracy: 0.5392 - 9s/epoch - 420ms/step\n",
            "Epoch 13/1000\n",
            "22/22 - 9s - loss: 0.6400 - accuracy: 0.6266 - val_loss: 0.6536 - val_accuracy: 0.6037 - 9s/epoch - 420ms/step\n",
            "Epoch 14/1000\n",
            "22/22 - 9s - loss: 0.6362 - accuracy: 0.6382 - val_loss: 0.6539 - val_accuracy: 0.5668 - 9s/epoch - 428ms/step\n",
            "Epoch 15/1000\n",
            "22/22 - 9s - loss: 0.6348 - accuracy: 0.6347 - val_loss: 0.6621 - val_accuracy: 0.5668 - 9s/epoch - 420ms/step\n",
            "Epoch 16/1000\n",
            "22/22 - 9s - loss: 0.6194 - accuracy: 0.6555 - val_loss: 0.6391 - val_accuracy: 0.5899 - 9s/epoch - 420ms/step\n",
            "Epoch 17/1000\n",
            "22/22 - 9s - loss: 0.6301 - accuracy: 0.6405 - val_loss: 0.7027 - val_accuracy: 0.5392 - 9s/epoch - 424ms/step\n",
            "Epoch 18/1000\n",
            "22/22 - 9s - loss: 0.6110 - accuracy: 0.6520 - val_loss: 0.6439 - val_accuracy: 0.6037 - 9s/epoch - 427ms/step\n",
            "Epoch 19/1000\n",
            "22/22 - 9s - loss: 0.5957 - accuracy: 0.6855 - val_loss: 0.7416 - val_accuracy: 0.5806 - 9s/epoch - 426ms/step\n",
            "Epoch 20/1000\n",
            "22/22 - 9s - loss: 0.5991 - accuracy: 0.6740 - val_loss: 0.6472 - val_accuracy: 0.6313 - 9s/epoch - 424ms/step\n",
            "Epoch 21/1000\n",
            "22/22 - 9s - loss: 0.5886 - accuracy: 0.6867 - val_loss: 0.6226 - val_accuracy: 0.6221 - 9s/epoch - 420ms/step\n",
            "Epoch 22/1000\n",
            "22/22 - 9s - loss: 0.5902 - accuracy: 0.6763 - val_loss: 0.6522 - val_accuracy: 0.6313 - 9s/epoch - 428ms/step\n",
            "Epoch 23/1000\n",
            "22/22 - 9s - loss: 0.5947 - accuracy: 0.6844 - val_loss: 0.6226 - val_accuracy: 0.6544 - 9s/epoch - 420ms/step\n",
            "Epoch 24/1000\n",
            "22/22 - 9s - loss: 0.5931 - accuracy: 0.6751 - val_loss: 0.6074 - val_accuracy: 0.6544 - 9s/epoch - 423ms/step\n",
            "Epoch 25/1000\n",
            "22/22 - 9s - loss: 0.5792 - accuracy: 0.7087 - val_loss: 0.5913 - val_accuracy: 0.6682 - 9s/epoch - 420ms/step\n",
            "Epoch 26/1000\n",
            "22/22 - 9s - loss: 0.5622 - accuracy: 0.7110 - val_loss: 0.5743 - val_accuracy: 0.7005 - 9s/epoch - 430ms/step\n",
            "Epoch 27/1000\n",
            "22/22 - 9s - loss: 0.5517 - accuracy: 0.7145 - val_loss: 0.5747 - val_accuracy: 0.6728 - 9s/epoch - 422ms/step\n",
            "Epoch 28/1000\n",
            "22/22 - 9s - loss: 0.5461 - accuracy: 0.7087 - val_loss: 0.5758 - val_accuracy: 0.6959 - 9s/epoch - 420ms/step\n",
            "Epoch 29/1000\n",
            "22/22 - 9s - loss: 0.5256 - accuracy: 0.7329 - val_loss: 0.5480 - val_accuracy: 0.7327 - 9s/epoch - 420ms/step\n",
            "Epoch 30/1000\n",
            "22/22 - 10s - loss: 0.5210 - accuracy: 0.7387 - val_loss: 0.5324 - val_accuracy: 0.7327 - 10s/epoch - 432ms/step\n",
            "Epoch 31/1000\n",
            "22/22 - 9s - loss: 0.5081 - accuracy: 0.7653 - val_loss: 0.5252 - val_accuracy: 0.7327 - 9s/epoch - 419ms/step\n",
            "Epoch 32/1000\n",
            "22/22 - 9s - loss: 0.5098 - accuracy: 0.7491 - val_loss: 0.6036 - val_accuracy: 0.6728 - 9s/epoch - 420ms/step\n",
            "Epoch 33/1000\n",
            "22/22 - 9s - loss: 0.5096 - accuracy: 0.7434 - val_loss: 0.5134 - val_accuracy: 0.7465 - 9s/epoch - 424ms/step\n",
            "Epoch 34/1000\n",
            "22/22 - 9s - loss: 0.4850 - accuracy: 0.7607 - val_loss: 0.5024 - val_accuracy: 0.7604 - 9s/epoch - 427ms/step\n",
            "Epoch 35/1000\n",
            "22/22 - 9s - loss: 0.4851 - accuracy: 0.7803 - val_loss: 0.5169 - val_accuracy: 0.7465 - 9s/epoch - 420ms/step\n",
            "Epoch 36/1000\n",
            "22/22 - 9s - loss: 0.4511 - accuracy: 0.7861 - val_loss: 0.5008 - val_accuracy: 0.7465 - 9s/epoch - 420ms/step\n",
            "Epoch 37/1000\n",
            "22/22 - 9s - loss: 0.4692 - accuracy: 0.7665 - val_loss: 0.5570 - val_accuracy: 0.7327 - 9s/epoch - 419ms/step\n",
            "Epoch 38/1000\n",
            "22/22 - 9s - loss: 0.4306 - accuracy: 0.8058 - val_loss: 0.5001 - val_accuracy: 0.7788 - 9s/epoch - 425ms/step\n",
            "Epoch 39/1000\n",
            "22/22 - 9s - loss: 0.4434 - accuracy: 0.7827 - val_loss: 0.4715 - val_accuracy: 0.7465 - 9s/epoch - 422ms/step\n",
            "Epoch 40/1000\n",
            "22/22 - 9s - loss: 0.4185 - accuracy: 0.8231 - val_loss: 0.4977 - val_accuracy: 0.7742 - 9s/epoch - 419ms/step\n",
            "Epoch 41/1000\n",
            "22/22 - 9s - loss: 0.4177 - accuracy: 0.8104 - val_loss: 0.4717 - val_accuracy: 0.7834 - 9s/epoch - 420ms/step\n",
            "Epoch 42/1000\n",
            "22/22 - 9s - loss: 0.4241 - accuracy: 0.7965 - val_loss: 0.4559 - val_accuracy: 0.7834 - 9s/epoch - 424ms/step\n",
            "Epoch 43/1000\n",
            "22/22 - 9s - loss: 0.3958 - accuracy: 0.8312 - val_loss: 0.4508 - val_accuracy: 0.7834 - 9s/epoch - 419ms/step\n",
            "Epoch 44/1000\n",
            "22/22 - 9s - loss: 0.3930 - accuracy: 0.8335 - val_loss: 0.4644 - val_accuracy: 0.8018 - 9s/epoch - 420ms/step\n",
            "Epoch 45/1000\n",
            "22/22 - 9s - loss: 0.3965 - accuracy: 0.8150 - val_loss: 0.4372 - val_accuracy: 0.8018 - 9s/epoch - 419ms/step\n",
            "Epoch 46/1000\n",
            "22/22 - 9s - loss: 0.3685 - accuracy: 0.8405 - val_loss: 0.5056 - val_accuracy: 0.7742 - 9s/epoch - 420ms/step\n",
            "Epoch 47/1000\n",
            "22/22 - 9s - loss: 0.3703 - accuracy: 0.8382 - val_loss: 0.4255 - val_accuracy: 0.8249 - 9s/epoch - 419ms/step\n",
            "Epoch 48/1000\n",
            "22/22 - 9s - loss: 0.3620 - accuracy: 0.8405 - val_loss: 0.4165 - val_accuracy: 0.8249 - 9s/epoch - 418ms/step\n",
            "Epoch 49/1000\n",
            "22/22 - 9s - loss: 0.3743 - accuracy: 0.8277 - val_loss: 0.4286 - val_accuracy: 0.8203 - 9s/epoch - 419ms/step\n",
            "Epoch 50/1000\n",
            "22/22 - 9s - loss: 0.3480 - accuracy: 0.8555 - val_loss: 0.3873 - val_accuracy: 0.8203 - 9s/epoch - 421ms/step\n",
            "Epoch 51/1000\n",
            "22/22 - 9s - loss: 0.3492 - accuracy: 0.8520 - val_loss: 0.4268 - val_accuracy: 0.8065 - 9s/epoch - 419ms/step\n",
            "Epoch 52/1000\n",
            "22/22 - 9s - loss: 0.3157 - accuracy: 0.8682 - val_loss: 0.4804 - val_accuracy: 0.8295 - 9s/epoch - 425ms/step\n",
            "Epoch 53/1000\n",
            "22/22 - 9s - loss: 0.3340 - accuracy: 0.8486 - val_loss: 0.4009 - val_accuracy: 0.8249 - 9s/epoch - 422ms/step\n",
            "Epoch 54/1000\n",
            "22/22 - 9s - loss: 0.3196 - accuracy: 0.8624 - val_loss: 0.4101 - val_accuracy: 0.8157 - 9s/epoch - 421ms/step\n",
            "Epoch 55/1000\n",
            "22/22 - 9s - loss: 0.2964 - accuracy: 0.8844 - val_loss: 0.4558 - val_accuracy: 0.8111 - 9s/epoch - 419ms/step\n",
            "Epoch 56/1000\n",
            "22/22 - 9s - loss: 0.3287 - accuracy: 0.8613 - val_loss: 0.4386 - val_accuracy: 0.8157 - 9s/epoch - 424ms/step\n",
            "Epoch 57/1000\n",
            "22/22 - 9s - loss: 0.3027 - accuracy: 0.8763 - val_loss: 0.3935 - val_accuracy: 0.8479 - 9s/epoch - 420ms/step\n",
            "Epoch 58/1000\n",
            "22/22 - 9s - loss: 0.3018 - accuracy: 0.8694 - val_loss: 0.3593 - val_accuracy: 0.8433 - 9s/epoch - 424ms/step\n",
            "Epoch 59/1000\n",
            "22/22 - 9s - loss: 0.2880 - accuracy: 0.8855 - val_loss: 0.3861 - val_accuracy: 0.8433 - 9s/epoch - 418ms/step\n",
            "Epoch 60/1000\n",
            "22/22 - 9s - loss: 0.2900 - accuracy: 0.8763 - val_loss: 0.3643 - val_accuracy: 0.8664 - 9s/epoch - 421ms/step\n",
            "Epoch 61/1000\n",
            "22/22 - 9s - loss: 0.2705 - accuracy: 0.8844 - val_loss: 0.3766 - val_accuracy: 0.8525 - 9s/epoch - 419ms/step\n",
            "Epoch 62/1000\n",
            "22/22 - 9s - loss: 0.2431 - accuracy: 0.9029 - val_loss: 0.3851 - val_accuracy: 0.8479 - 9s/epoch - 423ms/step\n",
            "Epoch 63/1000\n",
            "22/22 - 9s - loss: 0.3030 - accuracy: 0.8832 - val_loss: 0.3904 - val_accuracy: 0.8479 - 9s/epoch - 421ms/step\n",
            "Epoch 64/1000\n",
            "22/22 - 9s - loss: 0.2668 - accuracy: 0.8879 - val_loss: 0.3401 - val_accuracy: 0.8525 - 9s/epoch - 419ms/step\n",
            "Epoch 65/1000\n",
            "22/22 - 9s - loss: 0.2507 - accuracy: 0.8983 - val_loss: 0.4104 - val_accuracy: 0.8203 - 9s/epoch - 420ms/step\n",
            "Epoch 66/1000\n",
            "22/22 - 9s - loss: 0.2684 - accuracy: 0.8832 - val_loss: 0.3793 - val_accuracy: 0.8387 - 9s/epoch - 424ms/step\n",
            "Epoch 67/1000\n",
            "22/22 - 9s - loss: 0.2279 - accuracy: 0.9029 - val_loss: 0.3522 - val_accuracy: 0.8525 - 9s/epoch - 419ms/step\n",
            "Epoch 68/1000\n",
            "22/22 - 9s - loss: 0.2171 - accuracy: 0.9110 - val_loss: 0.3191 - val_accuracy: 0.8756 - 9s/epoch - 425ms/step\n",
            "Epoch 69/1000\n",
            "22/22 - 9s - loss: 0.2498 - accuracy: 0.9075 - val_loss: 0.3466 - val_accuracy: 0.8571 - 9s/epoch - 418ms/step\n",
            "Epoch 70/1000\n",
            "22/22 - 9s - loss: 0.2328 - accuracy: 0.9064 - val_loss: 0.4058 - val_accuracy: 0.8571 - 9s/epoch - 422ms/step\n",
            "Epoch 71/1000\n",
            "22/22 - 9s - loss: 0.2248 - accuracy: 0.9064 - val_loss: 0.3627 - val_accuracy: 0.8479 - 9s/epoch - 422ms/step\n",
            "Epoch 72/1000\n",
            "22/22 - 9s - loss: 0.2152 - accuracy: 0.9145 - val_loss: 0.3407 - val_accuracy: 0.8618 - 9s/epoch - 419ms/step\n",
            "Epoch 73/1000\n",
            "22/22 - 9s - loss: 0.2111 - accuracy: 0.9168 - val_loss: 0.3982 - val_accuracy: 0.8203 - 9s/epoch - 419ms/step\n",
            "Epoch 74/1000\n",
            "22/22 - 9s - loss: 0.2624 - accuracy: 0.8890 - val_loss: 0.3783 - val_accuracy: 0.8433 - 9s/epoch - 430ms/step\n",
            "Epoch 75/1000\n",
            "22/22 - 9s - loss: 0.2174 - accuracy: 0.9145 - val_loss: 0.3043 - val_accuracy: 0.8802 - 9s/epoch - 423ms/step\n",
            "Epoch 76/1000\n",
            "22/22 - 9s - loss: 0.1853 - accuracy: 0.9399 - val_loss: 0.3753 - val_accuracy: 0.8525 - 9s/epoch - 419ms/step\n",
            "Epoch 77/1000\n",
            "22/22 - 9s - loss: 0.2029 - accuracy: 0.9202 - val_loss: 0.3090 - val_accuracy: 0.8848 - 9s/epoch - 420ms/step\n",
            "Epoch 78/1000\n",
            "22/22 - 9s - loss: 0.2157 - accuracy: 0.9214 - val_loss: 0.2930 - val_accuracy: 0.8940 - 9s/epoch - 423ms/step\n",
            "Epoch 79/1000\n",
            "22/22 - 9s - loss: 0.1732 - accuracy: 0.9341 - val_loss: 0.3373 - val_accuracy: 0.8571 - 9s/epoch - 419ms/step\n",
            "Epoch 80/1000\n",
            "22/22 - 9s - loss: 0.1737 - accuracy: 0.9329 - val_loss: 0.3651 - val_accuracy: 0.8710 - 9s/epoch - 420ms/step\n",
            "Epoch 81/1000\n",
            "22/22 - 9s - loss: 0.1748 - accuracy: 0.9306 - val_loss: 0.3450 - val_accuracy: 0.8525 - 9s/epoch - 419ms/step\n",
            "Epoch 82/1000\n",
            "22/22 - 9s - loss: 0.1914 - accuracy: 0.9283 - val_loss: 0.4040 - val_accuracy: 0.8664 - 9s/epoch - 421ms/step\n",
            "Epoch 83/1000\n",
            "22/22 - 9s - loss: 0.1755 - accuracy: 0.9364 - val_loss: 0.2838 - val_accuracy: 0.8571 - 9s/epoch - 418ms/step\n",
            "Epoch 84/1000\n",
            "22/22 - 9s - loss: 0.1571 - accuracy: 0.9387 - val_loss: 0.3504 - val_accuracy: 0.8756 - 9s/epoch - 419ms/step\n",
            "Epoch 85/1000\n",
            "22/22 - 9s - loss: 0.1520 - accuracy: 0.9306 - val_loss: 0.4053 - val_accuracy: 0.8433 - 9s/epoch - 425ms/step\n",
            "Epoch 86/1000\n",
            "22/22 - 9s - loss: 0.1762 - accuracy: 0.9353 - val_loss: 0.3040 - val_accuracy: 0.8848 - 9s/epoch - 424ms/step\n",
            "Epoch 87/1000\n",
            "22/22 - 9s - loss: 0.1655 - accuracy: 0.9410 - val_loss: 0.2879 - val_accuracy: 0.8756 - 9s/epoch - 419ms/step\n",
            "Epoch 88/1000\n",
            "22/22 - 9s - loss: 0.1566 - accuracy: 0.9410 - val_loss: 0.5251 - val_accuracy: 0.8111 - 9s/epoch - 419ms/step\n",
            "Epoch 89/1000\n",
            "22/22 - 9s - loss: 0.1593 - accuracy: 0.9399 - val_loss: 0.3127 - val_accuracy: 0.8571 - 9s/epoch - 419ms/step\n",
            "Epoch 90/1000\n",
            "22/22 - 9s - loss: 0.1759 - accuracy: 0.9249 - val_loss: 0.3221 - val_accuracy: 0.8802 - 9s/epoch - 420ms/step\n",
            "Epoch 91/1000\n",
            "22/22 - 9s - loss: 0.1433 - accuracy: 0.9561 - val_loss: 0.3570 - val_accuracy: 0.8618 - 9s/epoch - 419ms/step\n",
            "Epoch 92/1000\n",
            "22/22 - 9s - loss: 0.1283 - accuracy: 0.9538 - val_loss: 0.3904 - val_accuracy: 0.8756 - 9s/epoch - 419ms/step\n",
            "Epoch 93/1000\n",
            "22/22 - 9s - loss: 0.1160 - accuracy: 0.9607 - val_loss: 0.3207 - val_accuracy: 0.8894 - 9s/epoch - 419ms/step\n",
            "Epoch 94/1000\n",
            "22/22 - 9s - loss: 0.1141 - accuracy: 0.9572 - val_loss: 0.3278 - val_accuracy: 0.8756 - 9s/epoch - 422ms/step\n",
            "Epoch 95/1000\n",
            "22/22 - 9s - loss: 0.1508 - accuracy: 0.9503 - val_loss: 0.3765 - val_accuracy: 0.8618 - 9s/epoch - 427ms/step\n",
            "Epoch 96/1000\n",
            "22/22 - 9s - loss: 0.1090 - accuracy: 0.9642 - val_loss: 0.3118 - val_accuracy: 0.8986 - 9s/epoch - 419ms/step\n",
            "Epoch 97/1000\n",
            "22/22 - 9s - loss: 0.1073 - accuracy: 0.9618 - val_loss: 0.3117 - val_accuracy: 0.8710 - 9s/epoch - 418ms/step\n",
            "Epoch 98/1000\n",
            "22/22 - 9s - loss: 0.1317 - accuracy: 0.9514 - val_loss: 0.3582 - val_accuracy: 0.8571 - 9s/epoch - 420ms/step\n",
            "Epoch 99/1000\n",
            "22/22 - 9s - loss: 0.1280 - accuracy: 0.9526 - val_loss: 0.3826 - val_accuracy: 0.8571 - 9s/epoch - 419ms/step\n",
            "Epoch 100/1000\n",
            "22/22 - 9s - loss: 0.1232 - accuracy: 0.9503 - val_loss: 0.4082 - val_accuracy: 0.8571 - 9s/epoch - 419ms/step\n",
            "Epoch 101/1000\n",
            "22/22 - 9s - loss: 0.1140 - accuracy: 0.9561 - val_loss: 0.3688 - val_accuracy: 0.8848 - 9s/epoch - 420ms/step\n",
            "Epoch 102/1000\n",
            "22/22 - 9s - loss: 0.1181 - accuracy: 0.9538 - val_loss: 0.3611 - val_accuracy: 0.8940 - 9s/epoch - 420ms/step\n",
            "Epoch 103/1000\n",
            "22/22 - 9s - loss: 0.0926 - accuracy: 0.9723 - val_loss: 0.3858 - val_accuracy: 0.8894 - 9s/epoch - 424ms/step\n",
            "Epoch 104/1000\n",
            "22/22 - 9s - loss: 0.1019 - accuracy: 0.9607 - val_loss: 0.3402 - val_accuracy: 0.8986 - 9s/epoch - 419ms/step\n",
            "Epoch 105/1000\n",
            "22/22 - 9s - loss: 0.1230 - accuracy: 0.9503 - val_loss: 0.3780 - val_accuracy: 0.8710 - 9s/epoch - 419ms/step\n",
            "Epoch 106/1000\n",
            "22/22 - 9s - loss: 0.0998 - accuracy: 0.9630 - val_loss: 0.3339 - val_accuracy: 0.8848 - 9s/epoch - 420ms/step\n",
            "Epoch 107/1000\n",
            "22/22 - 9s - loss: 0.0986 - accuracy: 0.9549 - val_loss: 0.3228 - val_accuracy: 0.8940 - 9s/epoch - 419ms/step\n",
            "Epoch 108/1000\n",
            "22/22 - 9s - loss: 0.0829 - accuracy: 0.9688 - val_loss: 0.3371 - val_accuracy: 0.8894 - 9s/epoch - 420ms/step\n",
            "Epoch 109/1000\n",
            "22/22 - 9s - loss: 0.1139 - accuracy: 0.9572 - val_loss: 0.3055 - val_accuracy: 0.8710 - 9s/epoch - 420ms/step\n",
            "Epoch 110/1000\n",
            "22/22 - 9s - loss: 0.1092 - accuracy: 0.9607 - val_loss: 0.4886 - val_accuracy: 0.7880 - 9s/epoch - 425ms/step\n",
            "Epoch 111/1000\n",
            "22/22 - 9s - loss: 0.0933 - accuracy: 0.9630 - val_loss: 0.3864 - val_accuracy: 0.8433 - 9s/epoch - 419ms/step\n",
            "Epoch 112/1000\n",
            "22/22 - 9s - loss: 0.0688 - accuracy: 0.9769 - val_loss: 0.3307 - val_accuracy: 0.8802 - 9s/epoch - 419ms/step\n",
            "Epoch 113/1000\n",
            "22/22 - 9s - loss: 0.0801 - accuracy: 0.9734 - val_loss: 0.3253 - val_accuracy: 0.8802 - 9s/epoch - 420ms/step\n",
            "Epoch 114/1000\n",
            "22/22 - 9s - loss: 0.0653 - accuracy: 0.9757 - val_loss: 0.3462 - val_accuracy: 0.8710 - 9s/epoch - 428ms/step\n",
            "Epoch 115/1000\n",
            "22/22 - 9s - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.5146 - val_accuracy: 0.8479 - 9s/epoch - 419ms/step\n",
            "Epoch 116/1000\n",
            "22/22 - 9s - loss: 0.0768 - accuracy: 0.9734 - val_loss: 0.3777 - val_accuracy: 0.8664 - 9s/epoch - 425ms/step\n",
            "Epoch 117/1000\n",
            "22/22 - 9s - loss: 0.0772 - accuracy: 0.9711 - val_loss: 0.3658 - val_accuracy: 0.8802 - 9s/epoch - 419ms/step\n",
            "Epoch 118/1000\n",
            "22/22 - 9s - loss: 0.0761 - accuracy: 0.9746 - val_loss: 0.3683 - val_accuracy: 0.8848 - 9s/epoch - 424ms/step\n",
            "Epoch 119/1000\n",
            "22/22 - 9s - loss: 0.0569 - accuracy: 0.9803 - val_loss: 0.3412 - val_accuracy: 0.8940 - 9s/epoch - 419ms/step\n",
            "Epoch 120/1000\n",
            "22/22 - 9s - loss: 0.0706 - accuracy: 0.9711 - val_loss: 0.4181 - val_accuracy: 0.8618 - 9s/epoch - 419ms/step\n",
            "Epoch 121/1000\n",
            "22/22 - 9s - loss: 0.0511 - accuracy: 0.9815 - val_loss: 0.5484 - val_accuracy: 0.8525 - 9s/epoch - 419ms/step\n",
            "Epoch 122/1000\n",
            "22/22 - 9s - loss: 0.0846 - accuracy: 0.9653 - val_loss: 0.3479 - val_accuracy: 0.8894 - 9s/epoch - 429ms/step\n",
            "Epoch 123/1000\n",
            "22/22 - 9s - loss: 0.1541 - accuracy: 0.9434 - val_loss: 0.3405 - val_accuracy: 0.8664 - 9s/epoch - 419ms/step\n",
            "Epoch 124/1000\n",
            "22/22 - 9s - loss: 0.1339 - accuracy: 0.9387 - val_loss: 0.4209 - val_accuracy: 0.8571 - 9s/epoch - 419ms/step\n",
            "Epoch 125/1000\n",
            "22/22 - 9s - loss: 0.0866 - accuracy: 0.9699 - val_loss: 0.3709 - val_accuracy: 0.8664 - 9s/epoch - 420ms/step\n",
            "Epoch 126/1000\n",
            "22/22 - 9s - loss: 0.0844 - accuracy: 0.9723 - val_loss: 0.3391 - val_accuracy: 0.8894 - 9s/epoch - 421ms/step\n",
            "Epoch 127/1000\n",
            "22/22 - 9s - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.4231 - val_accuracy: 0.8479 - 9s/epoch - 422ms/step\n",
            "Epoch 128/1000\n",
            "22/22 - 9s - loss: 0.0709 - accuracy: 0.9723 - val_loss: 0.3308 - val_accuracy: 0.9124 - 9s/epoch - 421ms/step\n",
            "Epoch 129/1000\n",
            "22/22 - 9s - loss: 0.0846 - accuracy: 0.9665 - val_loss: 0.3586 - val_accuracy: 0.8848 - 9s/epoch - 419ms/step\n",
            "Epoch 130/1000\n",
            "22/22 - 9s - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.4521 - val_accuracy: 0.8710 - 9s/epoch - 420ms/step\n",
            "Epoch 131/1000\n",
            "22/22 - 9s - loss: 0.0495 - accuracy: 0.9838 - val_loss: 0.4125 - val_accuracy: 0.8848 - 9s/epoch - 419ms/step\n",
            "Epoch 132/1000\n",
            "22/22 - 9s - loss: 0.0505 - accuracy: 0.9815 - val_loss: 0.3688 - val_accuracy: 0.8940 - 9s/epoch - 419ms/step\n",
            "Epoch 133/1000\n",
            "22/22 - 9s - loss: 0.0612 - accuracy: 0.9757 - val_loss: 0.3293 - val_accuracy: 0.8894 - 9s/epoch - 419ms/step\n",
            "Epoch 134/1000\n",
            "22/22 - 9s - loss: 0.0438 - accuracy: 0.9850 - val_loss: 0.4177 - val_accuracy: 0.8664 - 9s/epoch - 420ms/step\n",
            "Epoch 135/1000\n",
            "22/22 - 9s - loss: 0.0572 - accuracy: 0.9792 - val_loss: 0.3567 - val_accuracy: 0.8894 - 9s/epoch - 419ms/step\n",
            "Epoch 136/1000\n",
            "22/22 - 9s - loss: 0.0783 - accuracy: 0.9676 - val_loss: 0.4234 - val_accuracy: 0.8571 - 9s/epoch - 420ms/step\n",
            "Epoch 137/1000\n",
            "22/22 - 9s - loss: 0.0661 - accuracy: 0.9734 - val_loss: 0.4139 - val_accuracy: 0.8848 - 9s/epoch - 420ms/step\n",
            "Epoch 138/1000\n",
            "22/22 - 9s - loss: 0.0647 - accuracy: 0.9746 - val_loss: 0.3578 - val_accuracy: 0.8894 - 9s/epoch - 424ms/step\n",
            "Epoch 139/1000\n",
            "22/22 - 9s - loss: 0.0684 - accuracy: 0.9746 - val_loss: 0.5088 - val_accuracy: 0.8249 - 9s/epoch - 419ms/step\n",
            "Epoch 140/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7033cb9789d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1378\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1248\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    676\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(x=X, y=y, batch_size=40, validation_split = 0.2, epochs=1000, shuffle=True, verbose = 2, callbacks=[save_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J05JHTrNoZTL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c1d71673-c2b0-4719-df6c-fedf983ad34d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3ab0debc9bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yUgob2oBQET",
        "outputId": "3ed76f29-88d0-4bc7-d3bc-9f5be13fe7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content.gdrive/MyDrive/NN_945_ohne_Dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content.gdrive/MyDrive/NN_945_ohne_Dense/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f98b04a0150> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content.gdrive/MyDrive/NN_945_ohne_Dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l1_HfnSCgtC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "with open('/content.gdrive/MyDrive/Datasets_1575/data_Manually_Labeled_09042022.json', \"r\") as fp:\n",
        "    data2 = json.load(fp)\n",
        "# convert lists to numpy arrays\n",
        "X2 = np.array(data2[\"keypoints\"])\n",
        "y2 = np.array(data2[\"labels\"])\n",
        "\n",
        "predictions = model.predict(X2, batch_size = 10, verbose =0)\n",
        "\n",
        "print(predictions, y2)\n",
        "counter =0\n",
        "for i, x in enumerate(predictions):\n",
        "    if np.around(x) != y2[i]:\n",
        "        counter+=1\n",
        "print(y2.shape)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV0-fXTYC7p-"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content.gdrive/MyDrive/Model_1575_norm_crop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwXZ5JzbncjU"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpUifyJ-nhpq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NN_1575_norm_crop.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8ay7RTxHc0+snWth9YDpF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}